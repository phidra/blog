<!doctype html>
<html lang="fr-fr">
  <head>
    <title>Articles, talks, blogposts, et autres liens // Phidra&#39;s blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.73.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    
    <meta name="author" content="phidra" />
    

    
    <meta name="description" content="blog tech C&#43;&#43; python dev" />
    

    <link rel="stylesheet" href="https://phidra.github.io/blog/css/main.min.e5d131409cac231aa780bea0095dbf1d95c4563e65c24d2dfe3dd767c289c2de.css" />

    

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  </head>
  <body>
    <header class="app-header">

      
      
      <a href="https://phidra.github.io/blog/" id="avatar">
          <img src="/blog/img/general/phi_medium_fond_blanc.png" alt="phidra" />
      </a>
      

      <a href="https://phidra.github.io/blog/">
        <h1 class="title">Phidra&#39;s blog</h1>
      </a>

      
      <input class="burger" type="checkbox">
      <nav>
        <a href="https://phidra.github.io/blog/">                <i class="material-icons"> home </i>Posts       </a>
        <a href="https://phidra.github.io/blog/menu/notes/">      <i class="material-icons"> event_note </i>Notes       </a>
        <a href="https://phidra.github.io/blog/menu/references/"> <i class="material-icons"> menu_book </i>Références  </a>
        <a href="https://phidra.github.io/blog/menu/about/">      <i class="material-icons"> info </i>À propos    </a>
      </nav>

    </header>

    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Articles, talks, blogposts, et autres liens</h1>
      <div class="post-meta">
        <div>
          Jan 1, 2020
          —
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          68 min read
        </div></div>
    </header>
    <div class="post-content">
      <div id="preamble">
<div class="sectionbody">
<div class="paragraph">
<p> <details open><summary> 
Liste des liens
 </summary><div> </p>
</div>
<div id="toc" class="toc">
<div id="toctitle" class="title"></div>
<ul class="sectlevel1">
<li><a href="#_pourquoi_cette_page">Pourquoi cette page</a></li>
<li><a href="#__post_a_href_http_codefol_io_posts_urban_legend_of_the_10x_developer_the_urban_legend_of_the_10x_developer_a">[POST] <a href="http://codefol.io/posts/urban-legend-of-the-10x-developer/">The Urban Legend of the 10X Developer</a></a></li>
<li><a href="#__cours_a_href_https_www_supinfo_com_cours_2ads_chapitres_05_programmation_dynamique_programmation_dynamique_a">[COURS] <a href="https://www.supinfo.com/cours/2ADS/chapitres/05-programmation-dynamique">Programmation dynamique</a></a></li>
<li><a href="#__video_a_href_https_ocw_mit_edu_courses_electrical_engineering_and_computer_science_6_006_introduction_to_algorithms_fall_2011_lecture_videos_lecture_1_algorithmic_thinking_peak_finding_lecture_1_algorithmic_thinking_peak_finding_a">[VIDEO] <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/lecture-videos/lecture-1-algorithmic-thinking-peak-finding/">Lecture 1: Algorithmic Thinking, Peak Finding</a></a></li>
<li><a href="#__article_a_href_https_lucumr_pocoo_org_2020_1_1_async_pressure_i_m_not_feeling_the_async_pressure_a">[ARTICLE] <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">I&#8217;m not feeling the async pressure</a></a></li>
<li><a href="#__article_a_href_https_medium_com_jayphelps_backpressure_explained_the_flow_of_data_through_software_2350b3e77ce7_backpressure_explained_the_resisted_flow_of_data_through_software_a">[ARTICLE] <a href="https://medium.com/@jayphelps/backpressure-explained-the-flow-of-data-through-software-2350b3e77ce7">Backpressure explained — the resisted flow of data through software</a></a></li>
<li><a href="#__article_a_href_https_eklitzke_org_crcs_vs_hash_functions_crc_vs_hash_functions_a">[ARTICLE] <a href="https://eklitzke.org/crcs-vs-hash-functions">CRC vs hash functions</a></a></li>
<li><a href="#__article_a_href_https_eklitzke_org_how_tcp_sockets_work_how_tcp_sockets_work_a">[ARTICLE] <a href="https://eklitzke.org/how-tcp-sockets-work">How TCP Sockets Work</a></a></li>
<li><a href="#__article_a_href_https_cacm_acm_org_magazines_2013_2_160173_the_tail_at_scale_fulltext_the_tail_at_scale_a">[ARTICLE] <a href="https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext">The Tail at Scale</a></a></li>
<li><a href="#__article_a_href_https_www_nngroup_com_articles_response_times_3_important_limits_response_times_the_3_important_limits_a">[ARTICLE] <a href="https://www.nngroup.com/articles/response-times-3-important-limits/">Response Times: The 3 Important Limits</a></a></li>
<li><a href="#__post_a_href_https_instagram_engineering_com_dismissing_python_garbage_collection_at_instagram_4dca40b29172_dismissing_python_garbage_collection_at_instagram_a">[POST] <a href="https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172">Dismissing Python Garbage Collection at Instagram</a></a></li>
<li><a href="#__gist_a_href_https_gist_github_com_hellerbarde_2843375_latency_numbers_every_programmer_should_know_a">[GIST] <a href="https://gist.github.com/hellerbarde/2843375">Latency numbers every programmer should know</a></a></li>
<li><a href="#__post_a_href_https_robertovitillo_com_what_every_developer_should_know_about_tcp_what_every_developer_should_know_about_tcp_a">[POST] <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">What every developer should know about TCP</a></a></li>
<li><a href="#__post_a_href_https_www_justsoftwaresolutions_co_uk_cplusplus_invariants_html_invariants_and_preconditions_a">[POST] <a href="https://www.justsoftwaresolutions.co.uk/cplusplus/invariants.html">Invariants and Preconditions</a></a></li>
<li><a href="#__video_a_href_https_channel9_msdn_com_shows_going_deep_c_and_beyond_2012_andrei_alexandrescu_systematic_error_handling_in_c_systematic_error_handling_in_c_a_aussi_sur_a_href_https_www_youtube_com_watch_v_kai4r0ng4e8_youtube_a">[VIDEO] <a href="https://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Andrei-Alexandrescu-Systematic-Error-Handling-in-C">Systematic error handling in C++</a>, aussi sur <a href="https://www.youtube.com/watch?v=kaI4R0Ng4E8">youtube</a></a></li>
<li><a href="#__video_a_href_https_www_youtube_com_watch_v_obt_vmvdm8s_understanding_the_python_gil_a_voir_aussi_le_a_href_http_dabeaz_com_gil_post_qui_va_avec_a">[VIDEO] <a href="https://www.youtube.com/watch?v=Obt-vMVdM8s">Understanding the Python GIL</a>, voir aussi le <a href="http://dabeaz.com/GIL/">post qui va avec</a></a></li>
<li><a href="#__post_a_href_https_thomasvilhena_com_2019_08_a_successful_deployment_model_a_successful_deployment_model_a">[POST] <a href="https://thomasvilhena.com/2019/08/a-successful-deployment-model">A successful deployment model</a></a></li>
<li><a href="#__post_a_href_https_robertheaton_com_2020_04_06_systems_design_for_advanced_beginners_systems_design_for_advanced_beginners_a">[POST] <a href="https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/">Systems design for Advanced Beginners</a></a></li>
<li><a href="#__post_a_href_https_dropbox_tech_application_our_journey_to_type_checking_4_million_lines_of_python_our_journey_to_type_checking_4_million_lines_of_python_a">[POST] <a href="https://dropbox.tech/application/our-journey-to-type-checking-4-million-lines-of-python">Our journey to type checking 4 million lines of Python</a></a></li>
<li><a href="#__video_a_href_https_youtu_be_oq5jsbhav_m_19_dynamic_programming_i_fibonacci_shortest_paths_a">[VIDEO] <a href="https://youtu.be/OQ5jsbhAv_M">19. Dynamic Programming I: Fibonacci, Shortest Paths</a></a></li>
<li><a href="#__article_a_href_https_robbertkrebbers_nl_research_articles_safe_programming_rust_pdf_safe_systems_programming_in_rust_the_promise_and_the_challenge_a">[ARTICLE] <a href="https://robbertkrebbers.nl/research/articles/safe_programming_rust.pdf">Safe Systems Programming in Rust:The Promise and the Challenge</a></a></li>
<li><a href="#__post_a_href_https_amy_dev_p_783_my_coding_interview_style_a">[POST] <a href="https://amy.dev/?p=783">My Coding Interview Style</a></a></li>
<li><a href="#__video_a_id_video_sur_p_egal_np_a_a_href_https_www_youtube_com_watch_v_yx40hbahx3s_p_vs_np_et_le_zoo_de_complexité_informatique_a">[VIDEO] <a id="video-sur-P-egal-NP"></a><a href="https://www.youtube.com/watch?v=YX40hbAHx3s">P vs NP et le zoo de complexité informatique</a></a></li>
<li><a href="#__article_a_href_http_www_stroustrup_com_resource_model_pdf_a_brief_introduction_to_c_s_model_for_type_and_resource_safety_a">[ARTICLE] <a href="http://www.stroustrup.com/resource-model.pdf">A brief introduction to C++’s model for type- and resource-safety</a></a></li>
<li><a href="#__post_a_href_https_stackoverflow_blog_2020_03_05_a_modern_hello_world_program_needs_more_than_just_code_a_modern_hello_world_program_needs_more_than_just_code_a">[POST] <a href="https://stackoverflow.blog/2020/03/05/a-modern-hello-world-program-needs-more-than-just-code/">A modern ‘Hello, World’ program needs more than just code</a></a></li>
<li><a href="#__article_a_href_https_www_research_ed_ac_uk_portal_files_78829292_low_cost_deterministic_c_exceptions_for_embedded_systems_pdf_low_cost_deterministic_c_exceptions_for_embedded_systems_a">[ARTICLE] <a href="https://www.research.ed.ac.uk/portal/files/78829292/low_cost_deterministic_C_exceptions_for_embedded_systems.pdf">Low-Cost Deterministic C++ Exceptions for Embedded Systems</a></a></li>
<li><a href="#__site_a_href_https_benchmarksgame_team_pages_debian_net_benchmarksgame_the_computer_language_benchmarks_game_a">[SITE] <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/">The Computer Language Benchmarks Game</a></a></li>
<li><a href="#__video_a_href_https_www_youtube_com_watch_v_3lrmi5nodxu_l_api_management_au_delà_des_promesses_a">[VIDEO] <a href="https://www.youtube.com/watch?v=3Lrmi5NOdxU">L&#8217;API Management : au-delà des promesses</a></a></li>
<li><a href="#__post_a_href_https_cor3ntin_github_io_posts_abi_the_day_the_standard_library_died_a">[POST] <a href="https://cor3ntin.github.io/posts/abi/">The Day The Standard Library Died</a></a></li>
<li><a href="#__post_a_href_https_danluu_com_monorepo_advantages_of_monorepos_a">[POST] <a href="https://danluu.com/monorepo/">Advantages of monorepos</a></a></li>
<li><a href="#__site_a_href_https_yosefk_com_c_fqa_fqa_html_c_frequently_questioned_answers_a">[SITE] <a href="https://yosefk.com/c++fqa/fqa.html">C&#43;&#43; Frequently Questioned Answers</a></a></li>
<li><a href="#__post_a_href_https_hakibenita_com_fast_load_data_python_postgresql_fastest_way_to_load_data_into_postgresql_using_python_a">[POST] <a href="https://hakibenita.com/fast-load-data-python-postgresql">Fastest Way to Load Data Into PostgreSQL Using Python</a></a></li>
<li><a href="#__post_a_href_https_www_joelonsoftware_com_2003_10_13_13_exceptions_a">[POST] <a href="https://www.joelonsoftware.com/2003/10/13/13/">Exceptions</a></a></li>
<li><a href="#__post_a_href_https_blog_octo_com_reussir_la_developer_experience_de_son_api_web_réussir_la_developer_experience_de_son_api_web_a">[POST] <a href="https://blog.octo.com/reussir-la-developer-experience-de-son-api-web/">Réussir la Developer eXperience de son API web</a></a></li>
<li><a href="#__post_a_href_https_blog_octo_com_designer_une_api_rest_designer_une_api_rest_a">[POST] <a href="https://blog.octo.com/designer-une-api-rest/">Designer une API REST</a></a></li>
<li><a href="#__post_a_href_https_anaxi_com_blog_2019_02_20_how_to_make_other_developers_hate_to_work_with_you_how_to_make_other_developers_hate_to_work_with_you_a">[POST] <a href="https://anaxi.com/blog/2019/02/20/how-to-make-other-developers-hate-to-work-with-you/">How to Make Other Developers Hate to Work with You</a></a></li>
<li><a href="#__post_a_href_https_blog_feabhas_com_2014_03_demystifying_c_lambdas_demystifying_c_lambdas_a">[POST] <a href="https://blog.feabhas.com/2014/03/demystifying-c-lambdas/">Demystifying C++ lambdas</a></a></li>
<li><a href="#__stackoverflow_a_href_https_stackoverflow_com_questions_7586939_is_int_safe_to_read_from_multiple_threads_7587008_7587008_is_int_safe_to_read_from_multiple_threads_a">[STACKOVERFLOW] <a href="https://stackoverflow.com/questions/7586939/is-int-safe-to-read-from-multiple-threads/7587008#7587008">Is int safe to read from multiple threads?</a></a></li>
<li><a href="#__post_a_href_https_manybutfinite_com_post_motherboard_chipsets_memory_map_motherboard_chipsets_and_the_memory_map_a">[POST] <a href="https://manybutfinite.com/post/motherboard-chipsets-memory-map/">Motherboard Chipsets and the Memory Map</a></a></li>
<li><a href="#__post_a_id_liens_avec_des_notes_un_peu_touffues_a_a_href_https_lexi_lambda_github_io_blog_2019_11_05_parse_don_t_validate_parse_don_t_validate_a">[POST] <a id="liens-avec-des-notes-un-peu-touffues"></a><a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, don&#8217;t validate</a></a></li>
<li><a href="#__site_a_href_https_pages_apigee_com_ebook_the_definitive_guide_to_api_management_register_html_the_definitive_guide_to_api_management_a">[SITE] <a href="https://pages.apigee.com/ebook-the-definitive-guide-to-api-management-register.html">The Definitive Guide to API Management</a></a></li>
<li><a href="#__post_a_href_https_blog_eleven_labs_com_fr_presentation_protocol_buffers_présentation_de_protocol_buffers_a">[POST] <a href="https://blog.eleven-labs.com/fr/presentation-protocol-buffers/">Présentation de Protocol Buffers</a></a></li>
<li><a href="#__post_a_href_https_evertpot_com_dropbox_post_api_dropbox_starts_using_post_and_why_this_is_poor_api_design_a">[POST] <a href="https://evertpot.com/dropbox-post-api/">Dropbox starts using POST, and why this is poor API design</a></a></li>
<li><a href="#__post_a_href_https_blog_philipphauer_de_dont_share_libraries_among_microservices_don_t_share_libraries_among_microservices_a">[POST] <a href="https://blog.philipphauer.de/dont-share-libraries-among-microservices/">Don&#8217;t Share Libraries among Microservices</a></a></li>
<li><a href="#__bbl_no_estimates">[BBL] No estimates</a></li>
</ul>
</div>
<div class="paragraph">
<p> </div></details> </p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_pourquoi_cette_page">Pourquoi cette page</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Je croise souvent des articles/vidéos/posts/etc. dont j&#8217;ai envie de garder quelque chose. Jusqu&#8217;ici, ma façon canonique de le faire était d&#8217;en "extraire" la connaissance et de trouver un endroit dans mes notes où l&#8217;ajouter.</p>
</div>
<div class="paragraph">
<p>Par exemple, après avoir regardé une <a href="#video-sur-P-egal-NP">vidéo sur les problèmes P et NP-difficiles</a>, je vais créer un fichier <code>notes/algorithmic_complexity.otl</code>, et y mettre ce que j&#8217;en aurais compris, reformulé et réorganisé à ma sauce, éventuellement en ajoutant le lien vers la vidéo en référence. Si par la suite j&#8217;enrichis ma connaissance du sujet, alors je complèterai ou corrigerai ce fichier.</p>
</div>
<div class="paragraph">
<p>Avantage : j&#8217;ai des notes structurées sur les sujets que j&#8217;ai étudiés. L&#8217;outil que j&#8217;utilise, <a href="https://www.vim.org/scripts/script.php?script_id=3515">vim-outliner</a>, produit un format texte facile à grepper, que je trouve particulièrement lisible. Le process de structuration et reformulation de l&#8217;information est <strong>très</strong> formateur puisqu&#8217;il me permet d&#8217;identifier les points mal compris.</p>
</div>
<div class="paragraph">
<p>Inconvénient : produires ces notes "raffinées" (dans le sens de "traitées pour en extraire l&#8217;essentiel") et structurées demande beaucoup de temps. Par ailleurs, je n&#8217;y mets que de l&#8217;info "académique", rarement partielle ou brute, et jamais ce qui est de l&#8217;ordre de l&#8217;opinion. De façon plus anecdotique, le format otl est parfois limitant, et elles sont compliquées à partager.</p>
</div>
<div class="paragraph">
<p>Je veux tester sur cette page une autre façon de prendre des notes, probablement complémentaire du process que je suivais jusqu&#8217;ici : j&#8217;empile en vrac les liens vers les références intéressantes, assorties de quelques notes assez brutes.</p>
</div>
<div class="sect2">
<h3 id="_ce_que_j_en_attends">Ce que j&#8217;en attends</h3>
<div class="ulist">
<ul>
<li>
<p>déjà, ça me permet de les partager plus simplement que l&#8217;arborescence de répertoires qu&#8217;est devenu mon projet <code>notes</code>.</p>
</li>
<li>
<p>mais surtout, le côté déstructuré, associé au fait que les notes peuvent être minimales (quelques point à retenir), voire inexistantes (la simple présence du lien étant le signe que j&#8217;ai eu envie de pérenniser l&#8217;article) rendront mon process certes moins poussé, mais plus simple : j&#8217;espère avoir moins d&#8217;inertie à jeter quelques notes sur des articles qui m&#8217;ont intéressés.</p>
</li>
<li>
<p>pour autant, il me reste possible de prendre des notes un peu plus touffues (e.g. <a href="#liens-avec-des-notes-un-peu-touffues">ici</a>), que je pourrais facilement convertir en notes structurées otl, ou en post.</p>
</li>
<li>
<p>même si la source reste textuelle (asciidoctor), le rendu HTML me permet des choses impossibles en textuel simple, à commencer par le formatage du code.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>La règle d&#8217;or que j&#8217;essaye (avec succès jusqu&#8217;ici, yay) de suivre est de n&#8217;inclure que des références consultées et terminées : pas de "à lire" ou "à finir de visionner".</p>
</div>
<div class="paragraph">
<p>Pour le moment, ça m&#8217;arrange plutôt d&#8217;avoir toutes les notes sur la même page web. Lorsque/si la page devient inutilisable du fait de sa taille, j&#8217;envisagerai d&#8217;autres pistes (pagination ? <a href="https://sebsauvage.net/wiki/doku.php?id=php:shaarli">shaarli</a> ?).</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_http_codefol_io_posts_urban_legend_of_the_10x_developer_the_urban_legend_of_the_10x_developer_a">[POST] <a href="http://codefol.io/posts/urban-legend-of-the-10x-developer/">The Urban Legend of the 10X Developer</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_08_sur_a_href_http_codefol_io_class_bare_http_codefol_io_a_blog_d_un_dev_anonyme_surtout_ruby">Lu le 2020-08-??, sur <a href="http://codefol.io/" class="bare">http://codefol.io/</a> , blog d&#8217;un dev anonyme (surtout ruby)</h3>
<div class="ulist">
<ul>
<li>
<p>l&#8217;article a un point de vue intéressant sur le mythe du dev 10x</p>
</li>
<li>
<p>pas de recherche et de donnée formelle sur le sujet</p>
</li>
<li>
<p>sujet difficile à quantifier de toutes façons</p>
</li>
<li>
<p>lien avec la façon dont l&#8217;organisation soutient le dev : <em>A lot of stories of 10X developers have their roots in “well supported by the company” situations.</em></p>
</li>
<li>
<p>point de vue pragmatique (que j&#8217;incline à partager) sur la rareté des dev 10x :</p>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>That’s not to say that “anybody could be one.” I think actual “solid, ordinary” developers who can do good work on many different types of projects are rare and underrated. But they’re not magic unicorns. They’re about as rare as good plumbers, good mechanics or good doctors. You wouldn’t expect to find one every time you hire a professional. But you’d also expect to be able to find one with some time, work and patience. They may already be booked solid, of course.</p>
</div>
</blockquote>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__cours_a_href_https_www_supinfo_com_cours_2ads_chapitres_05_programmation_dynamique_programmation_dynamique_a">[COURS] <a href="https://www.supinfo.com/cours/2ADS/chapitres/05-programmation-dynamique">Programmation dynamique</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_07_28_c_est_pas_très_clair_quand_le_cours_a_été_publié_fait_partie_d_un_a_href_https_www_supinfo_com_cours_2ads_cours_d_algorithmique_à_supinfo_a_présenté_par_a_href_https_www_supinfo_com_fr_news0870864f_e0af_4ba1_b2ff_d488f356ef03_aspx_laurent_godefroy_a_enseignant_là_bas">Lu le 2020-07-28, c&#8217;est pas très clair quand le cours a été publié. Fait partie d&#8217;un <a href="https://www.supinfo.com/cours/2ADS">cours d&#8217;algorithmique à Supinfo</a>, présenté par <a href="https://www.supinfo.com/fr/News0870864f-e0af-4ba1-b2ff-d488f356ef03.aspx">Laurent GODEFROY</a>, enseignant là-bas.</h3>
<div class="ulist">
<ul>
<li>
<p>présentation propre de la programmation dynamique, avec notamment deux très bons exemples (rendu de monnaie et sac-à-dos)</p>
</li>
<li>
<p>fait écho au cours d&#8217;Erik DEMAINE annoté plus bas</p>
</li>
<li>
<p>conditions d&#8217;application de la programmation dynamique :</p>
<div class="ulist">
<ul>
<li>
<p>problème découpable en sous-problèmes discrets</p>
</li>
<li>
<p>le problème a une <em>optimal substructure</em> : la combinaison de solutions optimales à des sous-problèmes doit donner naissance à une solution optimale au problème global</p>
</li>
<li>
<p>NdM : j&#8217;ajoute "les sous-problèmes se recouvrent" (sans quoi inutile de faire de la prog dynamique, on peut faire un classique divide-and-conquer)</p>
</li>
</ul>
</div>
</li>
<li>
<p>programmation dynamique =</p>
<div class="ulist">
<ul>
<li>
<p>expression du problème sous forme d&#8217;une relation de récurrence  &#8592; c&#8217;est la partie difficile</p>
</li>
<li>
<p>condition d&#8217;arrêt</p>
</li>
<li>
<p>memoization</p>
</li>
</ul>
</div>
</li>
<li>
<p>inconvénients de l&#8217;approche bottom-up = on peut se retrouver à calculer des valeurs intermédiaires inutiles (elles ne nous servent pas pour la solution)</p>
</li>
<li>
<p>inconvénients de l&#8217;approche top-down = on peut se retrouver à faire une trop grosse récursion, et à exploser la callstack (en revanche, on ne calcule que ce qui sert réelement)</p>
</li>
<li>
<p>la partie difficile est d&#8217;exprimer le problème sous forme d&#8217;une relation de récurrence. Par exemple celle pour le sac-à-dos est issue de ces considérations :</p>
<div class="ulist">
<ul>
<li>
<p>Les objets ont un poids <code>wi</code> et une valeur <code>vi</code>.</p>
</li>
<li>
<p>on récurse sur l&#8217;indice <code>i</code> de l&#8217;objet parmi les <code>N</code> objets (en partant de la fin du tableau des objets).</p>
</li>
<li>
<p>la donnée pertinente est <code>V[i][w]</code> = le valeur maximale qu&#8217;on peut transporter dans un sac de capacité <code>w</code>, en ne considérant que les <code>i</code> premiers objets. Elle est issue de la combinaison optimale des <code>i</code> premiers objets dans le tableau (ce sont les objets "restants", vu qu&#8217;on a commencé à la fin du tableau)</p>
</li>
<li>
<p>notamment, la relation de récurrence indique que lorsqu&#8217;on traite l&#8217;objet <code>i</code>, on retient le MAX entre :</p>
<div class="ulist">
<ul>
<li>
<p><code>vi + V[i-1][w-wi]</code> = la valeur optimale si ON METS l&#8217;objet <code>i</code> dans le sac</p>
</li>
<li>
<p><code>V[i-1][w]</code> = la valeur optimale si ON NE METS PAS l&#8217;objet <code>i</code> dans le sac</p>
</li>
</ul>
</div>
</li>
<li>
<p>en quelque sorte, ce max "choisit" si on mets ou non l&#8217;objet <code>i</code> dans le sac, en supposant connue la façon optimale d&#8217;agencer les <code>i-1</code> objets précédents dans un sac (de poids <code>w</code> ou <code>w-wi</code>).</p>
</li>
<li>
<p>et c&#8217;est ce qu&#8217;on veut au plus haut niveau : <code>V[N][W]</code> choisit si on mets le dernier objet (d&#8217;indice <code>N</code>) dans le sac de poids <code>W</code>, en supposant connue la meillere façon de mettre les <code>N-1</code> objets dans un sac de capacité <code>W</code> (si on ne retient pas l&#8217;objet <code>N</code>) ou de capacité <code>W-wn</code> (si on retient l&#8217;objet <code>N</code>)</p>
</li>
</ul>
</div>
</li>
<li>
<p>à noter qu&#8217;il est plus simple de commencer par exprimer la relation de récurrence et l&#8217;algo en supposant que ce qui nous intéressent c&#8217;est la VALEUR recherchée, et pas la façon dont elle est construite :</p>
<div class="ulist">
<ul>
<li>
<p>dans le cadre du rendu de monnaie, commencer par se limiter à rechercher le nombre de pièces minimal</p>
</li>
<li>
<p>dans le cadre du sac à dos, commencer par se limiter à rechercher la valeur maximale</p>
</li>
<li>
<p>dans le cadre de Bellman-Ford, commencer par rechercher le poids du plus court chemin</p>
</li>
</ul>
</div>
</li>
<li>
<p>complexité pour le problème du sac-à-dos :</p>
<div class="ulist">
<ul>
<li>
<p>à noter que lorsque la complexité algorithmique dépend d&#8217;une <strong>VALEUR</strong> plutôt que d&#8217;une <strong>TAILLE</strong>, on l&#8217;exprime sous forme du nombre de bits de sa représentation, i.e. <code>complexité_VALEUR = log2(VALEUR)</code></p>
</li>
<li>
<p>ici, l&#8217;approche bottom-up avec deux boucles imbriquées montre que la complexité est en <code>N.W</code> où <code>N</code> est le nombre d&#8217;objets, et <code>W</code> la capacité du sac-à-dos</p>
</li>
<li>
<p><strong>MAIS</strong> comme la capacité est une valeur, on utilise son nombre de bits : <code>W = 2 ^ log2(W) = 2 ^ complexité_W</code>, et la complexité de l&#8217;algo est en fait exponentielle en la taille de <code>W</code></p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_href_https_ocw_mit_edu_courses_electrical_engineering_and_computer_science_6_006_introduction_to_algorithms_fall_2011_lecture_videos_lecture_1_algorithmic_thinking_peak_finding_lecture_1_algorithmic_thinking_peak_finding_a">[VIDEO] <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/lecture-videos/lecture-1-algorithmic-thinking-peak-finding/">Lecture 1: Algorithmic Thinking, Peak Finding</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_visionnée_le_2020_07_08_cours_publiée_le_2013_01_13_mais_semble_mur_a_href_https_www_youtube_com_channel_ucebb1b_l6zds3xturialzow_la_chaîne_mit_opencourseware_a_mais_semble_plutôt_correspondre_à_un_cours_présenté_en_2011_présenté_par_srini_devadas_professeur_au_mit_la_vidéo_fait_partie_de_la_série_de_cours_a_href_https_ocw_mit_edu_courses_electrical_engineering_and_computer_science_6_006_introduction_to_algorithms_fall_2011_introduction_to_algorithms_a">Visionnée le 2020-07-08, cours publiée le 2013-01-13 mais semble mur <a href="https://www.youtube.com/channel/UCEBb1b_L6zDS3xTUrIALZOw">la chaîne MIT OpenCourseWare</a> (mais semble plutôt correspondre à un cours présenté en 2011) , présenté par Srini DEVADAS, professeur au MIT. La vidéo fait partie de la série de cours <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/">Introduction to Algorithms</a>.</h3>
<div class="sect3">
<h4 id="_oveview">oveview</h4>
<div class="ulist">
<ul>
<li>
<p>16:15 définition du problème 1D</p>
</li>
<li>
<p>18:43 algo naïf en O(n) = parcours linéaire du tableau</p>
</li>
<li>
<p>24:40 algo efficace en O(logn), détaillé ci-dessous</p>
</li>
<li>
<p>33:35 étude de la complexité 1D</p>
</li>
<li>
<p>36:15 définition du problème 2D</p>
</li>
<li>
<p>37:20 algo naïf en O(n²) = greedy ascent</p>
</li>
<li>
<p>45:00 algo efficace&#8230;&#8203; mais incorrect !</p>
</li>
<li>
<p>47:00 algo efficace et correct divide-and-conquer en O(m x logn), détaillé ci-dessous</p>
</li>
<li>
<p>51:20 étude de la complexité 2D</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_objectif_trouver_un_peak">objectif = trouver un peak</h4>
<div class="ulist">
<ul>
<li>
<p>définition d&#8217;un peak ⛰ = une cellule supérieure ou égale à ses voisines</p>
</li>
<li>
<p>la définition reste vraie sur un bord, une cellule peut être un peak même si elle a moins de voisines que les autres cellules</p>
</li>
<li>
<p>en 2D, on parle d&#8217;une 4-connexité : les voisines sont les 4 cellules au nord, sud, est et ouest</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_algo_proposé_en_1d">algo proposé en 1D</h4>
<div class="ulist">
<ul>
<li>
<p>1. on prend la cellule au milieu du tableau, cellule pivot <strong>P</strong>, on regarde son voisin de gauche et son voisin de droite :</p>
<div class="linear-graph"><table><tr>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td class="bg-darkorange" > ?      </td>
    <td class="bg-royalblue"  > P      </td>
    <td class="bg-darkorange" > ?      </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
<div class="ulist">
<ul>
<li>
<p>si les deux voisins sont inférieurs, on a trouvé notre peak \o/</p>
</li>
<li>
<p>si les deux voisins sont supérieurs, on jette une moitié au hasard (y compris la cellule pivot), et on garde l&#8217;autre moitié</p>
</li>
<li>
<p>si seul l&#8217;un des voisins est supérieur, on jette toutes les cellules de la moitié <strong>DU CÔTÉ INFÉRIEUR</strong> (y compris la cellule pivot), et on garde l&#8217;autre moitié</p>
</li>
</ul>
</div>
</li>
<li>
<p>2. on recommence à l&#8217;étape 1 avec ce nouveau sous-tableau :</p>
<div class="linear-graph"><table><tr>
    <td                       > &nbsp; </td>
    <td class="bg-darkorange" > ?      </td>
    <td class="bg-royalblue"  > P      </td>
    <td class="bg-darkorange" > ?      </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
</tr> </table> </div>
</li>
<li>
<p>3. si on n&#8217;a pas arrêté avant, quand il ne reste plus qu&#8217;une cellule dans le sous-tableau, c&#8217;est forcément un peak</p>
<div class="linear-graph"><table><tr>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-green"      > ⛰       </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
    <td class="bg-grey"       > ✘      </td>
</tr> </table> </div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_pourquoi_l_algo_1d_fonctionne">Pourquoi l&#8217;algo 1D fonctionne</h4>
<div class="paragraph">
<p>Ça repose sur la relation entre le MAX local à un sous-tableau, et le peak ⛰.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>constat n°1 = tout sous-tableau du tableau 1D donné en entrée contient une cellule MAX sur le sous-tableau (il peut y en avoir plusieurs en cas d&#8217;égalité, ça ne change rien)</p>
</li>
<li>
<p>constat n°2 = quel que soit le sous-tableau extrait du tableau donné en entrée, tout MAX du sous-tableau est forcément un peak recherché, <strong>À CONDITION</strong> qu&#8217;il ne soit pas sur un bord du sous-tableau</p>
<div class="ulist">
<ul>
<li>
<p>considérons le sous-tableau suivant :</p>
<div class="linear-graph"><table><tr>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td class="bg-royalblue"  > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
<li>
<p>toute cellule MAX du sous-tableau est (par définition) supérieure ou égale à ses deux voisines, à condition que celles-ci soient aussi dans le sous-tableau. Dans ce cas, le MAX est un peak.</p>
</li>
<li>
<p>et cette condition est vérifiée si la cellule MAX n&#8217;est pas au bord du sous-tableau. Ci-dessous, si le MAX est l&#8217;une des cellules vertes, c&#8217;est un peak :</p>
<div class="linear-graph"><table><tr>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td class="bg-darkorange" > ?      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-darkorange" > ?      </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
<li>
<p>si le sous-tableau est collé au bord de son tableau parent, vue la définition du peak sur le bord, la cellule de bord du tableau sera également un peak si c&#8217;est un MAX : la seule cellule litigieuse qui reste est celle sur le bord du sous-tableau, et au MILIEU du tableau parent :</p>
<div class="linear-graph"><table><tr>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-darkorange" > ?      </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
</ul>
</div>
</li>
<li>
<p>si le MAX du sous-tableau est sur la cellule orange ci-dessus, on ne peut rien dire en l&#8217;état :</p>
<div class="ulist">
<ul>
<li>
<p>il se peut que ce ne soit pas un peak, si sa voisine de droite lui est supérieure :</p>
<div class="linear-graph"><table><tr>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-red"        > 3      </td>
    <td                       > 8 </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
<li>
<p>mais il se peut que ce soit un peak, si sa voisine de droite lui est inférieure :</p>
<div class="linear-graph"><table><tr>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > 8      </td>
    <td                       > 3 </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
<li>
<p>constat n°3 = dit autrement, tout MAX d&#8217;un sous-tableau quelconque est forcément un peak recherché si et seulement si la dernière cellule du sous-tableau est supérieure à sa première voisine en dehors du sous-tableau :</p>
<div class="linear-graph"><table><tr>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > ✔      </td>
    <td class="bg-green"      > GROS      </td>
    <td                       > petit </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
    <td                       > &nbsp; </td>
</tr> </table> </div>
</li>
</ul>
</div>
</li>
<li>
<p>ainsi, en choisissant le sous-tableau de sorte que sa dernière cellule soit supérieure à sa voisine hors du sous-tableau, trouver le max global d&#8217;un sous-tableau quelconque permet de trouver un peak du tableau complet donné en entrée</p>
</li>
<li>
<p>à partir de ces constats, l&#8217;idée de l&#8217;algo va être de choisir des sous-tableaux de plus en plus petits, par rapport à une cellule pivot :</p>
<div class="ulist">
<ul>
<li>
<p>lorsqu&#8217;on évalue la cellule pivot, pour garantir la propriété nécessaire, on choisit de conserver le sous-tableau (gauche ou droite) de sorte que la cellule pivot (qui sera donc la voisine de la cellule extrême du sous-tableau) soit INFÉRIEURE à sa voisine dans le sous-tableau</p>
</li>
<li>
<p>ainsi, à chaque étape, on garantit que le MAX du sous-tableau retenu sera bien un PEAK du tableau 1D donné en entrée</p>
</li>
<li>
<p>si on ne s&#8217;est pas arrêté avant, lorsque notre sous-tableau n&#8217;a plus qu&#8217;une seule cellule, c&#8217;est forcément son maximum global, et donc le peak recherché</p>
</li>
<li>
<p>CQFD :-)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_algo_proposé_en_2d">algo proposé en 2D</h4>
<div class="ulist">
<ul>
<li>
<p>1. on prend la colonne au milieu du tableau, colonne pivot P :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"  > P      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"  > P      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"  > P      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"  > P      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
</li>
<li>
<p>2. on la parcourt entièrement pour trouver sa cellule maximale ↑</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"  > ↑      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
</li>
<li>
<p>3. on regarde les voisins de gauche et de droite de la cellule maximale ↑ :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-darkorange"> &nbsp; </td>
        <td class="bg-royalblue"  > ↑      </td>
        <td class="bg-darkorange"> &nbsp; </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > &nbsp      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
<div class="ulist">
<ul>
<li>
<p>si les deux voisins sont inférieurs, on a trouvé notre peak \o/</p>
</li>
<li>
<p>si les deux voisins sont supérieurs, on jette une moitié des colonnes au hasard (y compris la colonne pivot), et on garde l&#8217;autre moitié des colonnes</p>
</li>
<li>
<p>si seul l&#8217;un des voisins est supérieur, on jette toutes les colonnes de la moitié <strong>DU CÔTÉ INFÉRIEUR</strong> (y compris la colonne pivot), et on garde l&#8217;autre moitié des colonnes</p>
</li>
</ul>
</div>
</li>
<li>
<p>4. on recommence à l&#8217;étape 1 avec ce nouveau sous-tableau :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"> P </td>
        <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"> P </td>
        <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"> P </td>
        <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-royalblue"> P </td>
        <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
</table> </div>
</li>
<li>
<p>5. si on n&#8217;a pas arrêté avant, quand il ne reste plus qu&#8217;une colonne, son max est forcément un peak</p>
<div class="linear-graph"><table>
    <tr>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
        <td class="bg-green"> ⛰ </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
    <tr>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td>
        <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td> <td class="bg-grey"> ✘ </td>
    </tr>
</table> </div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_pourquoi_l_algo_2d_fonctionne">Pourquoi l&#8217;algo 2D fonctionne</h4>
<div class="ulist">
<ul>
<li>
<p>pour les mêmes raisons qu&#8217;en 1D : on construit à chaque étape un sous-ensemble (un subset de colonnes) tel que tout MAX sur ce sous-ensemble est aussi un peak de la matrice 2D complète</p>
</li>
<li>
<p>comme précédemment, presque tout MAX sur le sous-ensemble est en fait <strong>DÉJÀ</strong> un peak de la matrice 2D complète :</p>
<div class="ulist">
<ul>
<li>
<p>c&#8217;est le cas <strong>À COUP SÛR</strong> si le MAX n&#8217;est pas sur la colonne adjacente à la colonne pivot</p>
</li>
<li>
<p>c&#8217;est <strong>PEUT-ÊTRE</strong> le cas si le MAX est sur la colonne A, adjacente à la colonne pivot</p>
</li>
<li>
<p>pour que ce soit le cas dans cette dernière situation, il faut que toute cellule MAX sur la colonne A soit supérieure à sa voisine sur la colonne pivot</p>
</li>
</ul>
</div>
</li>
<li>
<p>rechercher la plus grande cellule de la colonne pivot, et choisir de garder les colonnes du côté supérieur à celle-ci garantit que cette propriété est vraie :</p>
<div class="ulist">
<ul>
<li>
<p>en effet, par définition, la plus grande cellule de la colonne pivot est supériere à toutes les autres cellules de la colonne pivot :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-darkorange"> &nbsp; </td>
        <td class="bg-royalblue"  > ↑      </td>
        <td class="bg-darkorange"> &nbsp; </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
</li>
<li>
<p>et comme on ne garde que les colonnes du côté où la voisine (marquée <code>&gt;</code> ci-dessous) est <strong>plus grande</strong> que la plus grande cellule de la colonne pivot, toutes les cellules de la colonne pivot lui sont inférieures :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-darkorange"> > </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
</li>
<li>
<p>&#8230;&#8203; et cette voisine sera elle-même inférieure ou égale au MAX (noté <code>M</code> ci-dessous) du subset de colonnes (rappel : on s&#8217;intéresse au cas où ce MAX est située sur la colonne adjacente à la colonne pivot). Donc par transitivité, en construisant le subset de colonnes tel que décrit, même s&#8217;il est situé sur la "mauvaise" colonne, le MAX <code>M</code> sera forcément supérieur a sa voisine sur la colonne pivot :</p>
<div class="linear-graph"><table>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td class="bg-grey"  > &nbsp;      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-darkorange"> < </td>
        <td class="bg-grey"  > &nbsp;      </td>
        <td> &nbsp; </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-grey"  > <      </td>
        <td class="bg-grey"  > &nbsp;      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
    <tr>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
        <td class="bg-green"  > M      </td>
        <td class="bg-grey"  > <      </td>
        <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td> <td> &nbsp; </td>
    </tr>
</table> </div>
</li>
<li>
<p>donc le MAX <code>M</code> de cette colonne adjacente est également un peak ⛰ de la matrice 2D complète, CQFD</p>
</li>
</ul>
</div>
</li>
<li>
<p>dans ce qui précède, attention à ne pas confondre :</p>
<div class="ulist">
<ul>
<li>
<p>le peak ⛰  (qui porte sur toute la matrice 2D initiale) = une cellule supérieure à ses 4 voisines, ce qu&#8217;on recherche</p>
</li>
<li>
<p>la plus grande cellule de la colonne pivot (qui porte juste sur les cellules de la colonne pivot)</p>
</li>
<li>
<p>le MAX du subset des colonnes (qui porte juste sur une partie des colonnes de la matrice 2D initiale)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_greedy_algo_en_2d">greedy algo en 2D</h4>
<div class="ulist">
<ul>
<li>
<p>on trouvera forcément un peak local&#8230;&#8203;</p>
</li>
<li>
<p>&#8230;&#8203;si on n&#8217;a pas de pot, on parcourera tout le tableau ou presque avant de le trouver → O(N*M)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_lucumr_pocoo_org_2020_1_1_async_pressure_i_m_not_feeling_the_async_pressure_a">[ARTICLE] <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">I&#8217;m not feeling the async pressure</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_07_07_publié_le_2020_01_01_par_a_href_https_lucumr_pocoo_org_about_armin_ronacher_a_co_leader_de_a_href_http_www_pocoo_org_pocoo_a_un_groupe_de_dev_open_source_bossant_sur_des_projets_comme_sphinx_flask_werkzeug_ou_encore_pygments">Lu le 2020-07-07, publié le 2020-01-01 par <a href="https://lucumr.pocoo.org/about/">Armin RONACHER</a>, co-leader de <a href="http://www.pocoo.org/">pocoo</a>, un groupe de dev open-source bossant sur des projets comme sphinx, flask, werkzeug, ou encore pygments.</h3>
<div class="ulist">
<ul>
<li>
<p>point de vocabulaire = confusion (qui semble assumée) entre back pressure et back pressure management :</p>
<div class="ulist">
<ul>
<li>
<p>back pressure = resistance that opposes the flow of data through a system</p>
</li>
<li>
<p>back pressure management = moyen de faire en sorte que la back pressure ne pose pas problème</p>
</li>
<li>
<p>dans l&#8217;article (et <a href="https://github.com/aio-libs/aiohttp/issues/1368">ailleurs</a>), on peut lire des choses comme <em>this library doesn&#8217;t have back pressure</em>, mais il faut lire <em>this library doesn&#8217;t have back pressure MANAGEMENT</em></p>
</li>
</ul>
</div>
</li>
<li>
<p>exemple pris = la gestion des bagages dans un aéroport :</p>
<div class="ulist">
<ul>
<li>
<p>quand on veut faire voyager des bagages, on les mets (= produits) dans un container</p>
</li>
<li>
<p>lorsqu&#8217;un container est plein, il est alors chargé (= consommé) dans un avion</p>
</li>
<li>
<p>backpressure = quid si de nouveaux bagages arrivent alors qu&#8217;on n&#8217;a plus de containers de disponibles à charger ?</p>
</li>
</ul>
</div>
</li>
<li>
<p>les 3 stratégies possibles (cf. les notes précédentes ci-dessous) :</p>
<div class="ulist">
<ul>
<li>
<p>buffering = on garde le bagage de côté, et on attend qu&#8217;un nouveau container vide arrive</p>
</li>
<li>
<p>dropping = on brûle discrètement le bagage en trop sur le côté de l&#8217;aéroport</p>
</li>
<li>
<p>control the producer = on avertit l&#8217;aéroport de ne plus accepter de nouveau bagage</p>
</li>
</ul>
</div>
</li>
<li>
<p>pourquoi l&#8217;async a changé les choses ? quelle différence avec le code synchrone (multi-threadé) qu&#8217;on utilisait avant pour faire de l&#8217;IO bloquant ?</p>
<div class="ulist">
<ul>
<li>
<p>exemple donné avec un echo server</p>
</li>
<li>
<p>en asyncio : le serveur accepte toutes les connexions, y compris quand il ne pourra pas les traiter : mais si le write buffer est plein, la lib va bufferiser indéfiniment</p>
</li>
<li>
<p>en synchrone : lorsque le pool de threads capable d&#8217;accepter une connexion est vide (tous les threads sont occupés), la connexion va être mise en attente / refusée</p>
</li>
</ul>
</div>
</li>
<li>
<p>à noter qu&#8217;on peut très bien accepter plus que ce qu&#8217;on peut traiter, pour être sûr d&#8217;avoir toujours de quoi traiter : si on n&#8217;a que 50 connexions BDD possibles (ou 50 threads dans le pool), on peut accpeter 200 requêtes (4 x plus), une partie va attendre un peu, mais les threads/connexions seront exploitées à fond</p>
</li>
<li>
<p>la "bonne" façon de faire selon l&#8217;auteur :</p>
<div class="ulist">
<ul>
<li>
<p>le service doit être capable de connaître son état : "prêt à traiter" ou "surchargé, je ne traiterai pas une prochaine requête"</p>
</li>
<li>
<p>si une requête arrive alors que le service est surchargé, on retourne 503 (éventuellement, en indiquant dans combien de temps réessayer avec le header <code>retry-after</code>)</p>
</li>
<li>
<p>en gros : plutôt que d&#8217;essayer de répondre à toute requête qu&#8217;on nous passe (et c&#8217;est niveau OS que ça va bloquer), on faile early si on voit qu&#8217;on est surchargé</p>
</li>
</ul>
</div>
</li>
<li>
<p>cas du streaming :</p>
<div class="ulist">
<ul>
<li>
<p>ce qui est exposé ci-dessus marche bien pour des patterns de type request→response, mais pour des patterns de type stream c&#8217;est plus compliqué</p>
</li>
<li>
<p>normalement, <a href="https://en.wikipedia.org/wiki/Transmission_Control_Protocol#Flow_control">il y a du control-flow intégré dans TCP</a>, mais en pratique, des mécanismes de flow-control custom sont souvent implémentés par dessus. Par exemple, en HTTP2, plusieurs streams peuvent être multiplexés sur une seule connexion TCP, d&#8217;où le besoin d&#8217;un mécanisme custom de flow-control.</p>
</li>
<li>
<p>MAIS le fait que le mécanisme de flow-control de TCP soit plutôt invisible (en effet, il n&#8217;est pas accessible via l&#8217;API socket) est <strong>DANGEREUX</strong> : le dev PEUT faire comme si c&#8217;était transparent pour lui, alor qu&#8217;il FAUT qu&#8217;il prenne en compte le cas où il y a de la backpressure : lorsqu&#8217;on implémente un protocole de streaming, il FAUT qu&#8217;il soit bidirectionnel : du client vers le serveur pour envoyer les données <strong>ET</strong> du serveur vers le client pour réguler la vitesse</p>
</li>
<li>
<p>et ça c&#8217;est pas trivial du tout !</p>
</li>
</ul>
</div>
</li>
<li>
<p>le problème (ne pas gérer la backpressure) est commun à plein de monde : go, rust, aiohttp, etc.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_medium_com_jayphelps_backpressure_explained_the_flow_of_data_through_software_2350b3e77ce7_backpressure_explained_the_resisted_flow_of_data_through_software_a">[ARTICLE] <a href="https://medium.com/@jayphelps/backpressure-explained-the-flow-of-data-through-software-2350b3e77ce7">Backpressure explained — the resisted flow of data through software</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_07_07_publié_le_2019_02_01_sur_a_href_https_medium_com_jayphelps_la_page_medium_de_jay_phelps_a_dev_google_ancien_dev_netflix">Lu le 2020-07-07, publié le 2019-02-01 sur <a href="https://medium.com/@jayphelps">la page medium de Jay PHELPS</a>, dev google, ancien dev Netflix</h3>
<div class="ulist">
<ul>
<li>
<p>backpressure = résistance au flow</p>
</li>
<li>
<p>cas typique = un producteur de message, et un consommateur de message, la backpressure apparaît lorsque le producteur produit plus vite que le consommateur ne consomme</p>
</li>
<li>
<p>3 stratégies pour y faire face :</p>
<div class="ulist">
<ul>
<li>
<p><strong>buffering</strong> = on accumule les messages en trop dans un buffer, en espérant pouvoir les dépiler lorsque le pic de charge sera passé. <strong>inconvénient</strong> = attention à ce que le buffer ne grossisse pas indéfiniment + quid si le buffer est plein ?</p>
</li>
<li>
<p><strong>dropping</strong> = on droppe les messages en trop. <strong>inconvénient</strong> = on perd des messages.</p>
</li>
<li>
<p><strong>control the producer</strong> (flow control) = on avertit le producteur qu&#8217;il va trop vite, et qu&#8217;il doit ralentir. La meilleure solution si elle est disponible. <strong>inconvénient</strong> = pas toujours réalisable + peut-être compliquée à implémenter.</p>
</li>
</ul>
</div>
</li>
<li>
<p>exemple (tiré de cet <a href="https://lucumr.pocoo.org/2020/1/1/async-pressure/">autre excellent article</a>) : la gestion des bagages dans un aéroport : quand on veut faire voyager des bagages, on les mets (= produits) dans un container. Lorsqu&#8217;ils sont pleins, chaque container est alors chargé (= consommé) dans un avion. Quid si de nouveaux bagages arrivent alors qu&#8217;on n&#8217;a plus de containers de disponibles à charger ?</p>
<div class="ulist">
<ul>
<li>
<p>buffering = on garde le bagage de côté, et on attend qu&#8217;un nouveau container vide arrive</p>
</li>
<li>
<p>dropping = on brûle discrètement le bagage en trop sur le côté de l&#8217;aéroport</p>
</li>
<li>
<p>control the producer = on avertit l&#8217;aéroport de ne plus accepter de nouveau bagage</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_eklitzke_org_crcs_vs_hash_functions_crc_vs_hash_functions_a">[ARTICLE] <a href="https://eklitzke.org/crcs-vs-hash-functions">CRC vs hash functions</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_06_26_publié_le_2016_06_12_sur_le_a_href_https_eklitzke_org_blog_d_evan_klitzke_a_ex_dev_über_dev_bitcoin_core">Lu le 2020-06-26, publié le 2016-06-12 sur le <a href="https://eklitzke.org/">blog d&#8217;Evan KLITZKE</a> ex-dev über + dev bitcoin core</h3>
<div class="ulist">
<ul>
<li>
<p>CRC et hash functions semblent similaires : à partir d&#8217;une entrée quelconque, ils produisent une sortie "réduite" (checksum pour CRC, digest pour hash function), typiquement de 32 à 512 bits</p>
</li>
<li>
<p>objectif de CRC = détecter les erreurs de transmission :</p>
<div class="ulist">
<ul>
<li>
<p>mathématiquement, les 32bits-CRC de deux messages différents seront <strong>obligatoirement</strong> inégaux si la différence de message est &lt; 32 bits, quel que soit le message.</p>
</li>
<li>
<p>(ils seront <strong>sans doute</strong> inégaux même pour des différences plus importantes)</p>
</li>
<li>
<p>Mais même si les CRC sont inégaux, ils peuvent être très similaires, et on s&#8217;en fiche : l&#8217;important c&#8217;est qu&#8217;on puisse dire "si les CRC sont différents, le message a été altéré"</p>
</li>
</ul>
</div>
</li>
<li>
<p>objectif de hash = ne pas être biaisé en fonction de l&#8217;entrée :</p>
<div class="ulist">
<ul>
<li>
<p>deux messages différents <strong>mais très proches</strong> doivent produire des digest <strong>aussi dissemblables</strong> que deux messages différents <strong>et très éloignés</strong></p>
</li>
<li>
<p>dit autrement : étant donné deux digests différents, on ne doit pas être capables de dire si les messages initiaux étaient proches ou non (à la différence des CRC)</p>
</li>
<li>
<p>une autre façon de voir ça : si on change un seul bit sur un message d&#8217;entrée, chaque bit de son digest doit avoir une chance sur deux d&#8217;être modifié</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_eklitzke_org_how_tcp_sockets_work_how_tcp_sockets_work_a">[ARTICLE] <a href="https://eklitzke.org/how-tcp-sockets-work">How TCP Sockets Work</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_06_25_publié_le_2017_01_27_sur_le_a_href_https_eklitzke_org_blog_d_evan_klitzke_a_ex_dev_über_dev_bitcoin_core">Lu le 2020-06-25, publié le 2017-01-27 sur le <a href="https://eklitzke.org/">blog d&#8217;Evan KLITZKE</a> ex-dev über + dev bitcoin core</h3>
<div class="ulist">
<ul>
<li>
<p>TL;DR : explications de haut-niveau sur la stack TCP/IP Linux</p>
</li>
<li>
<p>quand un paquet arrive, le kernel est soit notifié (interrupt), soit polle le NIC (= network interface) pour savoir qu&#8217;il y a un nouveau paquet</p>
</li>
<li>
<p>le paquet est alors décodé, et attribué à une connexion TCP à partir de ip+port de source/destination</p>
</li>
<li>
<p>son payload est copié dans le receive buffer de la socket, puis "réveille" un éventuel read/select qui bloquait jusqu&#8217;ici</p>
</li>
<li>
<p>en userland, le process peut alors copier le contenu du receive buffer dans le buffer en userland (c&#8217;est ce que fait <code>read</code>, cf. <code>man 2 read</code>) &#8594; le receive buffer en kernelspace est vidé par cette opération</p>
</li>
<li>
<p>conséquence = si on appelle <code>read</code> trop rarement, le receive buffer peut grossir démesurément. Pour éviter ça, le kernel limite la taille du receive buffer&#8230;&#8203; qui peut donc finir par être plein si on <code>read</code> trop rarement !</p>
</li>
<li>
<p>en résumé, quand on appelle <code>read</code> :</p>
<div class="ulist">
<ul>
<li>
<p>si le receive buffer est vide, <code>read</code> bloque jusqu&#8217;à ce qu&#8217;on ait des données</p>
</li>
<li>
<p>si le receive buffer n&#8217;est pas vide, <code>read</code> retourne en copiant les données du receive buffer dans le userland buffer (éventuellement, partiellement si on n&#8217;en avait pas assez reçu)</p>
</li>
<li>
<p>si le receive buffer est plein, tout envoi de paquet sur la socket sera refusé par la pile TCP/IP (<code>ACK</code> ne sera pas envoyé). C&#8217;est ue partie de la <a href="https://en.wikipedia.org/wiki/TCP_congestion_control">TCP congestion control</a> , déjà évoqué dans l&#8217;article <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">What every developer should know about TCP</a></p>
</li>
</ul>
</div>
</li>
<li>
<p>(l&#8217;article détaille également le fonctionnement de <code>write</code>, je ne le reproduis pas ici)</p>
</li>
<li>
<p>c&#8217;est le même principe pour write (je ne détaille pas ici), ainsi que pour une listen-socket (chargée de spawner d&#8217;autres sockets en réponse aux tentatives de connexion par des clients) : si elle n'`accept` pas assez vite, le kernel va refuser les nouvelles connexions.</p>
</li>
<li>
<p>le mécanisme est donc similaire dans les 3 cas : <code>read</code> / <code>write</code> / <code>accept</code>, je l&#8217;illustre avec <code>read</code> :</p>
<div class="ulist">
<ul>
<li>
<p>on a une queue = le receive buffer</p>
</li>
<li>
<p>on a un producteur = les paquets reçus par la stack TCP/IP (resp. envoyés, ou les demandes de connexions)</p>
</li>
<li>
<p>on a un consommateur = les appels à <code>read</code> (resp. <code>write</code> / <code>accept</code>) pour vider la queue</p>
</li>
</ul>
</div>
</li>
<li>
<p>si le consommateur ne consomme pas assez vite, le kernel bloque (refuse de recevoir/envoyer de nouveaux paquets, ou bien refuse les nouvelles connexions)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_cacm_acm_org_magazines_2013_2_160173_the_tail_at_scale_fulltext_the_tail_at_scale_a">[ARTICLE] <a href="https://cacm.acm.org/magazines/2013/2/160173-the-tail-at-scale/fulltext">The Tail at Scale</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_05_21_publié_le_2013_20_sur_le_a_href_https_research_google_site_présentant_de_google_dédié_à_la_recherche_a">Lu le 2020-05-21, publié le 2013-20-?? sur le <a href="https://research.google/">site présentant de google dédié à la recherche</a></h3>
<div class="ulist">
<ul>
<li>
<p>TL;DR : article assez varié présentant les causes de latences dans le traitement des requêtes, et tout un tas de pistes pour y être robuste. Un point important : inutile de chercher à être <em>fault-free</em> : mieux vaut être <em>fault-tolerant</em>.</p>
</li>
<li>
<p>objectif = répondre en moins de 100 ms (quelques dizaines de ms pour le service de suggest du moteur de recherche de google)</p>
</li>
<li>
<p>même de rares augmentations de la latence dégradent l&#8217;ensemble des requêtes : plutôt que de viser à un système <strong>sans</strong> latence, il faut concevoir un système pour répondre rapidement <strong>même en présence</strong> de latence occasionnelle : <em>latency tail-tolerant</em></p>
</li>
<li>
<p>causes de latence "individuelle" (i.e. sans prendre en compte le fait qu&#8217;une requête est un agrégat complexe d&#8217;agents et de sous-requêtes) :</p>
<div class="ulist">
<ul>
<li>
<p><strong>compétition pour des ressources partagées localement</strong> : temps CPU, cache, memory bandwidth, network bandwidth, &#8230;&#8203;</p>
</li>
<li>
<p><strong>daemons</strong> : peu consommateur <em>en moyenne</em>, mais lorsqu&#8217;ils se déclenchent, peuvent consommer des ressources <em>en burst</em></p>
</li>
<li>
<p><strong>compétition pour des ressources partagées globalement</strong> : network switches, shared filesystems</p>
</li>
<li>
<p><strong>maintenance automatiques</strong> : e.g. passage du garbage collector d&#8217;un runtime (e.g. java)</p>
</li>
<li>
<p><strong>queuing</strong> : passage obligé dans une queue potentiellement déjà chargée</p>
</li>
<li>
<p><strong>hardware power limit</strong> : throttling automatique si le CPU chauffe trop</p>
</li>
<li>
<p><strong>hardware garbage collection</strong> : pour les SSD, il y a un GC hardware qui multiplie la latence par 100</p>
</li>
<li>
<p><strong>hardware energy management</strong> : latence nécessaire pour sortir d&#8217;un mode "économie d&#8217;énergie"</p>
</li>
</ul>
</div>
</li>
<li>
<p>même si on répartit les sous-requêtes sur différents sous-systèmes, la queue de la distribution va être limitante :</p>
<div class="ulist">
<ul>
<li>
<p>leur approche est de regarder le 99ième percentile de temps de réponse (d&#8217;où le "tail")</p>
</li>
<li>
<p>si les services répondent en 10 ms mais que le 99ième percentile répond en une seconde, une requête sur cent sera longue</p>
</li>
<li>
<p>sur un service qui requête 100 sous-serveurs en parallèle, 63% des requêtes prendra plus d&#8217;une seconde (1 - 0.99^100)</p>
</li>
<li>
<p>même si seule 1/10000 requête est lente, si on a besoin de 2000 sous-requêtes, alors 1 requêtes sur 5 (0.18 = 1 - 0.9999^2000) prendra plus d&#8217;une seconde</p>
</li>
</ul>
</div>
</li>
<li>
<p>comment diminuer cette latency-tail pour un composant donné ?</p>
<div class="ulist">
<ul>
<li>
<p>prioriser les éléments d&#8217;une queue qui sont destinés à servir une requête qu&#8217;un utilisateur final attend (par opposition aux requêtes où c&#8217;est pas très grave si ça prend ponctuellement du temps, par exemple pour des tâches automatiques)</p>
</li>
<li>
<p>autoriser la préemption des requêtes, pour éviter qu&#8217;une seule requête très lente bloque toutes celles derrière elle (en effet, celles-ci pourront préempter la requête lente au bout d&#8217;un moment)</p>
</li>
<li>
<p>limiter l&#8217;impact des activités en tâche de fond (e.g. en ne les lançant que lorsque l&#8217;activité est faible)</p>
</li>
<li>
<p>note : le caching est hors de propos ici, puisqu&#8217;il n&#8217;adresse pas le problème de la queue de la distribution (car les requêtes responsables de la queue de la latency-distribution ne sont pas cachées)</p>
</li>
</ul>
</div>
</li>
<li>
<p>étant donné qu&#8217;on ne pourra de toutes façons <strong>pas</strong> supprimer la latency-tail, comment réduire la sensibilité à celle-ci ?</p>
<div class="ulist">
<ul>
<li>
<p><strong>hedged requests</strong> :</p>
<div class="ulist">
<ul>
<li>
<p>profiter du fait que les serveurs soient répliqués en envoyant N fois la même requête en parallèle à différent serveur, en gardant la première réponse (et en discardant les suivantes)</p>
</li>
<li>
<p>pour ne pas surcharger le système inutilement, plutôt que de faire ça systématiquement, on ne le fait que lorsque la première requête met un peu de temps à répondre</p>
</li>
<li>
<p>en n&#8217;augmentant le volume des requêtes que de 2%, ils arrivent à réduire la latence du 99.9 percentile de 1800 ms à 74 ms !</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>tied requests</strong> :</p>
<div class="ulist">
<ul>
<li>
<p>proglème des hedged requêtes = on est coincés entre Charybde (sursolliciter les serveurs de façon inutile) et Scylla (devoir attendre avant de déclencher les requêtes supplémentaires).</p>
</li>
<li>
<p>l&#8217;une des causes principales des variabilités de latences est le temps de queuing des serveurs : une fois la requête en cours en cours de traitement par le serveur, la variabilité n&#8217;est pas énorme.</p>
</li>
<li>
<p>du coup solution simple = le load balancer tient compte de l&#8217;encombrement des queues pour choisir le serveur</p>
</li>
<li>
<p>solution alternative = enqueuer plusieurs requêtes en parallèle dans plusieurs serveurs, et leur permettre de communiquer : quand un serveur commence à traiter une requête, il transmet aux autres serveurs un message d&#8217;annulation de leur requête équivalente.</p>
</li>
<li>
<p>encore une autre alternative = avant de faire une requête à un serveur, on le probe pour savoir s&#8217;il est occupé. Cette solution créée d&#8217;autres problèmes : l&#8217;occupation du serveur peut augmenter entre la probe et la requête, il peut-être difficile à un serveur de savoir s&#8217;il est occupé, et ça peut occasionner un pic de charge sur un serveur considéré comme le moins occupé.</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>en temps normal, on essaye de partitionner le problème uniformément entre les ressources permettant de le résoudre. En pratique, d&#8217;une part les ressources ne répondent pas toutes de façon uniforme, et d&#8217;autre part une portion du problème peut prendre de l&#8217;importance <strong>après</strong> le partitionnement (e.g. si une recherche google se met à être à la mode). Pistes :</p>
<div class="ulist">
<ul>
<li>
<p><strong>micro-partition</strong> : si on a 10 serveurs, au lieu de partionner le problème en 10 morceaux, on le partitionne en 100, et chaque serveur en traite 10. Si l&#8217;une des micro-partitions  (on peut plus facilement redispatcher les micros-partitions si nécessaires)</p>
</li>
<li>
<p><strong>selective replication</strong> : répliquer dynamiquement les morceaux qui sont cause de surcharge, pour les faire traiter par plus de serveurs. Deux exemples :</p>
<div class="ulist">
<ul>
<li>
<p>sur 24h, en fonction des fuseaux horaires, la répartition des langues des requêtes change avec l&#8217;avancée des heures &#8594; on adapte les documents servis en répliquant les langues les plus populaires à une heure dite</p>
</li>
<li>
<p>si un data-center en Asie est down, on réplique dynamiquement les documents de langues asiatiques sur un serveur nord-américain pour répondre aux requêtes</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>latency-induced probation</strong> : on sort temporairement du flux un serveur qui semble occupé, par exemple par un autre job sur le serveur (paradoxalement, c&#8217;est donc en réduisant les ressources qu&#8217;on améliore la latence moyenne)</p>
</li>
</ul>
</div>
</li>
<li>
<p>dans les information retrieval systems , c&#8217;est plus important de renvoyer un bon résultat rapidement que de renvoyer le meilleur résultat lentement :</p>
<div class="ulist">
<ul>
<li>
<p><strong>good enough</strong> : de temps en temps, on n&#8217;attend pas que 100% des leaf-servers aient répondu, on se permet de répondre si une fraction suffisamment grande a déjà répondu, en supposant qu&#8217;il y a peu de chances que les réponses manquantes améliorent la réponse globale</p>
</li>
<li>
<p><strong>canary requests</strong> : un risque est qu&#8217;une requête particulière fasse emprunter un chemin de code buggé, qui fait planter TOUS les leaf servers d&#8217;un coup. Pour éviter ça, on envoie d&#8217;abord la requête à 1 ou 2 leaf-servers, et seulement s&#8217;ils répondent correctement, on envoie la requête à tout le monde.</p>
</li>
</ul>
</div>
</li>
<li>
<p>mutations : la latence sur les requêtes de mutation est plus simple à gérer :</p>
<div class="ulist">
<ul>
<li>
<p>souvent les attentes sont moindres</p>
</li>
<li>
<p>les mutations peuvent être effectuées <strong>après</strong> avoir répondu à l&#8217;utilisateur, donc sans se presser</p>
</li>
<li>
<p>les services nécessitant des mutations peuvent être structurés pour être plus latency-tolerant</p>
</li>
<li>
<p>lorsqu&#8217;on cherche à muter, souvent on utilise un algo (genre Lamport-Paxos) pour recueillir un consensus, et on n&#8217;a pas besoin de la queue de la distribution</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_www_nngroup_com_articles_response_times_3_important_limits_response_times_the_3_important_limits_a">[ARTICLE] <a href="https://www.nngroup.com/articles/response-times-3-important-limits/">Response Times: The 3 Important Limits</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_05_20_publié_le_1993_01_01_mis_à_jour_en_2014_l_article_reste_d_actualité_par_jakob_nielsen_un_spécialiste_de_l_ux_sur_le_site_du_a_href_https_www_nngroup_com_nielsen_norman_group_a_supposément_world_leaders_in_research_based_user_experience">Lu le 2020-05-20, publié le 1993-01-01 (mis à jour en 2014 : l&#8217;article reste d&#8217;actualité) par Jakob NIELSEN, un spécialiste de l&#8217;UX sur le site du <a href="https://www.nngroup.com/">Nielsen Norman Group</a>, supposément "World Leaders in Research-Based User Experience".</h3>
<div class="ulist">
<ul>
<li>
<p>3 temps de réponses pertinents :</p>
<div class="ulist">
<ul>
<li>
<p>&lt; 100 ms = le système semble répondre instantanément, l&#8217;utilisateur a l&#8217;impression d&#8217;agir <em>directement</em> sur les données</p>
</li>
<li>
<p>&lt; 1 seconde = l&#8217;utilisateur perd l&#8217;impression d&#8217;agir directement sur les données, mais le système n&#8217;interrompt pas le "flow of thoughts" de l&#8217;utilisateur</p>
</li>
<li>
<p>&lt; 10 secondes = le système interrompt le "flow of thoughts", mais est suffisamment réactif pour qu&#8217;on n&#8217;ait pas envie d&#8217;aller faire autre chose pendant qu&#8217;il mouline</p>
</li>
<li>
<p>&gt; 10 secondes = l&#8217;utilisateur va aller faire autre chose pendant que le système mouline &#8594; il <em>faut</em> lui donner un indicateur de "quand la tâche sera finie" (e.g. un indcateur de pourcentage restant, ou spinner)</p>
</li>
</ul>
</div>
</li>
<li>
<p>un peu plus de temps : <a href="https://www.nngroup.com/articles/powers-of-10-time-scales-in-ux/" class="bare">https://www.nngroup.com/articles/powers-of-10-time-scales-in-ux/</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_instagram_engineering_com_dismissing_python_garbage_collection_at_instagram_4dca40b29172_dismissing_python_garbage_collection_at_instagram_a">[POST] <a href="https://instagram-engineering.com/dismissing-python-garbage-collection-at-instagram-4dca40b29172">Dismissing Python Garbage Collection at Instagram</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_05_20_publié_le_2017_01_17_sur_a_href_https_instagram_engineering_com_le_blog_tech_d_instagram_a">Lu le 2020-05-20, publié le 2017-01-17 sur <a href="https://instagram-engineering.com/">le blog tech d&#8217;instagram</a></h3>
<div class="ulist">
<ul>
<li>
<p>sur un serveur instagram = django avec un process master qui forke pour spawner des douzaines de sous-process</p>
</li>
<li>
<p>lorsqu&#8217;un sous-process démarre, le RSS (resident set size) monte vite à 250 Mio, mais la fraction de la mémoire "partagée par les autres process" redescend vite à 140 Mio (ce qui montre que ~90 Mio sont devenus "propres au process forké" plutôt que "partagé avec le parent")</p>
</li>
<li>
<p>COW = copy-on-write = les sous-process partagent leurs memory-frames avec leur process parent, jusqu&#8217;à ce que celle-ci soit modifié par l&#8217;un ou l&#8217;autre</p>
</li>
<li>
<p>mais en python : même une lecture de variable modifie la memory frame (pour incrémenter le refcount) du coup, à la moindre lecture, le COW se déclenche (c&#8217;est en fait un &#8230;&#8203; COR = copy-on-read)</p>
</li>
<li>
<p>ils essayent de profiler d&#8217;abord, en monitorant les page-fault (vu que le mécanisme de COW fait un page-fault pour copier la memory frame) &#8594; surprise, c&#8217;est en fait le garbage collector qui génère le plus de page fault</p>
</li>
<li>
<p><code>gc.disable()</code> ne marche pas car une lib externe appelle <code>gc.enable()</code>, du coup ils ont utilisé <a href="https://docs.python.org/3/library/gc.html#gc.set_threshold">gc.set_threshold(0)</a></p>
</li>
<li>
<p>la désactivation du GC évite de trigger les COW, du coup la part de mémoire partagée entre le process master et ses fork remonte de 140 Mio à 225 Mio \o/</p>
</li>
<li>
<p>MAIS désactiver le GC présente un effet de bord : redémarrer leurs process sur le serveur devient d&#8217;un seul coup très lent (merci au continuous deployement pour l&#8217;avoir détecté) :</p>
<div class="ulist">
<ul>
<li>
<p>avant de s&#8217;arrêter, l&#8217;interpréteur python fait un dernier <code>gc.collect</code> (qui n&#8217;est pas bypassé par <code>gc.set_threshold(0)</code>)</p>
</li>
<li>
<p>du coup TOUTES les COW des processus fils se déclenchent en même temps, augmentant fortement la consommation de RAM d&#8217;un seul coup &#8594; il n&#8217;y a plus de RAM libre, et le page-cache se vide</p>
</li>
<li>
<p>du coup quand le process redémarre, au moment de recharger en RAM toutes les pages disques du processus, elles NE SONT PLUS dans le page cache, il faut les relire depuis le disque dur, ce qui est très lent</p>
</li>
</ul>
</div>
</li>
<li>
<p>pour éviter ça, ils bypassent le process de finalization de python (l&#8217;idée est : de toute façons, le process s&#8217;arrête &#8594; inutile de cleanup ou d&#8217;appeler gc)</p>
</li>
<li>
<p>question : disabler le GC n&#8217;est-il pas problématique ? Réponse : non, car le GC n&#8217;est là que pour briser les références cycliques, le mécanisme principal de désallocation est lorsque le refcount tombe à zéro.</p>
</li>
<li>
<p>bilan = 8Gio de RAM en moins consommée, mais surtout : amélioration de la vitesse d&#8217;exécution (mesurée en IPC = instruction CPU per cycle) :</p>
<div class="ulist">
<ul>
<li>
<p>en effet, à nombre de process identique, il y a moins de pages mémoire <strong>différentes</strong> existantes (vu qu&#8217;on a augmenté le <strong>partage</strong> des pages mémoires entre les process, en déclenchant moins souvent le COW)</p>
</li>
<li>
<p>et comme on a moins de pages mémoires différentes à code identique, on aura moins de cache-miss</p>
</li>
<li>
<p>or chaque cache-miss force le CPU à attendre, du coup diminuer les cache-miss implique qu&#8217;on augmente l&#8217;IPC \o/</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__gist_a_href_https_gist_github_com_hellerbarde_2843375_latency_numbers_every_programmer_should_know_a">[GIST] <a href="https://gist.github.com/hellerbarde/2843375">Latency numbers every programmer should know</a></h2>
<div class="sectionbody">
<div class="ulist">
<ul>
<li>
<p>résumé des ordres de grandeur des différentes latences</p>
</li>
<li>
<p>notamment :</p>
<div class="ulist">
<ul>
<li>
<p>L2 cache ~ 10x plus lent que L1 cache</p>
</li>
<li>
<p>main memory ~ 100x plus lent que L1 cache</p>
</li>
<li>
<p>disk seek+read ~ 10.000.000x plus lent que L1 cache</p>
</li>
</ul>
</div>
</li>
<li>
<p>les représentations visuelles et "humaines" sont top</p>
</li>
</ul>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_robertovitillo_com_what_every_developer_should_know_about_tcp_what_every_developer_should_know_about_tcp_a">[POST] <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">What every developer should know about TCP</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_05_15_publié_le_2020_05_10_par_a_href_https_robertovitillo_com_about_roberto_vitillo_a_dev_microsoft_ancien_dev_mozilla">Lu le 2020-05-15, publié le 2020-05-10 par <a href="https://robertovitillo.com/about">Roberto Vitillo</a>, dev Microsoft, ancien dev Mozilla</h3>
<div class="ulist">
<ul>
<li>
<p>RTT = round-trip time, qui dépend de la latency</p>
</li>
<li>
<p>TL;DR : latency et bandwidth ne sont pas indépendants. Plusieurs causes :</p>
<div class="ulist">
<ul>
<li>
<p>les handshakes TCP et TLS nécessitent plusieur RT &#8594; le moment où on pourra envoyer le <strong>premier</strong> paquet dépend de la latency</p>
</li>
<li>
<p>cold start = le sender maintient une <em>congestion window</em> , le temps qu&#8217;elle prend pour augmenter (et donc pour que la bandwidth augmente) dépend du RTT, donc de la latency</p>
</li>
<li>
<p>congestion control = le sender adapte ses envois de paquets en fonction du <em>receive buffer</em> du receiver &#8594; le temps pris pour revenir à la normale après un timeout dépend du RTT, donc de la latency</p>
</li>
</ul>
</div>
</li>
<li>
<p>réutiliser les connexions déjà ouvertes est une façon de mitiger les deux premiers points</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_www_justsoftwaresolutions_co_uk_cplusplus_invariants_html_invariants_and_preconditions_a">[POST] <a href="https://www.justsoftwaresolutions.co.uk/cplusplus/invariants.html">Invariants and Preconditions</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_05_07_publié_le_2020_03_05_par_anthony_williams_sur_a_href_https_www_justsoftwaresolutions_co_uk_class_bare_https_www_justsoftwaresolutions_co_uk_a_qui_semble_être_le_site_vitrine_de_consltants">Lu le 2020-05-07, publié le 2020-03-05 par Anthony WILLIAMS sur <a href="https://www.justsoftwaresolutions.co.uk/" class="bare">https://www.justsoftwaresolutions.co.uk/</a> qui semble être le site vitrine de consltants.</h3>
<div class="ulist">
<ul>
<li>
<p><strong>invariant</strong> = doit rester valable pour <strong>TOUTES</strong> les instances de l&#8217;objet.</p>
<div class="ulist">
<ul>
<li>
<p>y compris après un <code>move</code>, qui laisse l&#8217;objet dans un état "emptier than empty"</p>
</li>
<li>
<p>y compris avant un <code>init</code>, si des constructeurs défèrent la construction finale avec un <code>init</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>si les invariants sont vrais tout le temps, sauf dans ces cas&#8230;&#8203; c&#8217;est que ce ne sont pas des invariants !</p>
</li>
<li>
<p>dans le cas d&#8217;un <code>init</code>, plutôt que d&#8217;appeler ces "faux-invariants" des invariants, il est plus juste de considérer que <strong>TOUTES</strong> les méthodes de la classe <strong>SAUF</strong> <code>init</code> ont une précondition (qui est qu'`init` ait été appelé)</p>
</li>
<li>
<p>équivalent dans le cas du <code>move</code> : toutes les méthodes de la classe ont comme précondition que l&#8217;instance n&#8217;ait pas été <code>move</code>-ée.</p>
</li>
<li>
<p>de base, c&#8217;est ok que les méthodes de la classe brisent les invariants <em>temporairement</em> (par exemple, au cours d&#8217;un appel de méthode), tant que ceux-ci restent vrais avant et après l&#8217;appel de méthode.</p>
</li>
<li>
<p>mais dans ce cas attention au multithreading : si l&#8217;état de l&#8217;instance est visible par un thread B pendant qu&#8217;un thread A est dans une méthode qui brise "temporairement" l&#8217;invariant &#8594; le thread B a accès à une instance pour laquelle les invariants sont faux !</p>
</li>
<li>
<p>et ça peut arriver même si chaque ligne respecte les invariants : la thread-safety n&#8217;est pas composable</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_href_https_channel9_msdn_com_shows_going_deep_c_and_beyond_2012_andrei_alexandrescu_systematic_error_handling_in_c_systematic_error_handling_in_c_a_aussi_sur_a_href_https_www_youtube_com_watch_v_kai4r0ng4e8_youtube_a">[VIDEO] <a href="https://channel9.msdn.com/Shows/Going+Deep/C-and-Beyond-2012-Andrei-Alexandrescu-Systematic-Error-Handling-in-C">Systematic error handling in C++</a>, aussi sur <a href="https://www.youtube.com/watch?v=kaI4R0Ng4E8">youtube</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_vue_le_2020_04_27_publiée_par_andrei_alexandrescu_c_legend_à_l_occasion_de_https_cppandbeyond_com_c_and_beyond_2012_une_conf_organisée_par_scott_meyers_herbe_sutter_et_andrei_alexandrescu">Vue le 2020-04-27, publiée par Andrei ALEXANDRESCU, C legend, à l'occasion de https://cppandbeyond.com/[C and beyond 2012], une conf organisée par Scott MEYERS, Herbe SUTTER et Andrei ALEXANDRESCU.</h3>
<div class="ulist">
<ul>
<li>
<p>contexte = error handling :</p>
<div class="ulist">
<ul>
<li>
<p><em>error handling is about bad DATA (e.g. bad inputs), not bad STATE</em> &#8594; it&#8217;s not about bugs</p>
</li>
<li>
<p>exemple de situation qui n&#8217;est PAS de l&#8217;error handling = ram défecteuse, programme incorrect, &#8230;&#8203;</p>
</li>
<li>
<p>exemple de situation qui est de l&#8217;error handling = plus d&#8217;espace disque, on a demandé à l&#8217;utilisateur un entier, et il a entré <code>toto</code></p>
</li>
</ul>
</div>
</li>
<li>
<p>présentation de <code>Expected</code> (malheureusement toujours pas standard à l&#8217;heure où j&#8217;écris ces lignes), un peu l&#8217;équivalent des <code>Maybe</code> d&#8217;Haskell</p>
</li>
<li>
<p><code>Expected&lt;T&gt;</code> = contient soit <code>T</code>, soit l&#8217;exception qui a empêché d&#8217;avoir <code>T</code></p>
</li>
<li>
<p>l&#8217;essentiel du talk présente l&#8217;implémentation de <code>Expected</code> comme union de <code>T</code> et <code>std::exception_ptr</code></p>
</li>
<li>
<p>le reste du talk concerne ScopedGuard11, une intéressante forme de RAII (simplifiant la composabilité) : le principe reste du RAII : exécuter du code arbitraire (lambda) à la destruction, MAIS ça permet également d&#8217;annuler le code avec <code>sg.dismiss()</code></p>
</li>
<li>
<p>pour voir l&#8217;intérêt dans le cadre de la gestion d&#8217;erreur, cf. l&#8217;exemple de la vidéo. On cherche à composer deux tâches <code>action</code> et <code>next</code> (qui peuvent échouer et raise une exception), en sachant d&#8217;une part que si <code>action</code> réussit, elle va nécessiter du <code>cleanup</code>, et d&#8217;autre part que <code>action</code> et <code>next</code> doivent réussir toutes les deux ou échouer toutes les deux (transaction) : si <code>next</code> échoue, il faut donc <code>rollback</code> ce qu&#8217;a fait <code>action</code></p>
</li>
<li>
<p>façon "classique" avec RAII :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #66d9ef">class</span> <span style="color: #a6e22e">RAII</span> <span style="color: #f8f8f2">{</span>
<span style="color: #f8f8f2">RAII()</span> <span style="color: #f8f8f2">{</span> <span style="color: #f8f8f2">action();</span> <span style="color: #f8f8f2">}</span>
<span style="color: #f92672">~</span><span style="color: #f8f8f2">RAII()</span> <span style="color: #f8f8f2">{</span> <span style="color: #f8f8f2">cleanup();</span> <span style="color: #f8f8f2">}</span>
<span style="color: #f8f8f2">}</span>

<span style="color: #f8f8f2">RAII</span> <span style="color: #f8f8f2">raii;</span>
<span style="color: #66d9ef">try</span> <span style="color: #f8f8f2">{</span>
    <span style="color: #f8f8f2">next();</span>
<span style="color: #f8f8f2">}</span> <span style="color: #66d9ef">catch</span> <span style="color: #f8f8f2">(...)</span> <span style="color: #f8f8f2">{</span>
    <span style="color: #f8f8f2">rollback();</span>
    <span style="color: #66d9ef">throw</span><span style="color: #f8f8f2">;</span>
<span style="color: #f8f8f2">}</span></code></pre>
</div>
</div>
</li>
<li>
<p>le problème de ce qui précède, c&#8217;est la composabilité : si <code>next</code> est à son tour une transaction de <code>second_action</code> et <code>second_next</code>, le code devient horrible à cause des nested try-catch.</p>
</li>
<li>
<p>les <code>ScopedGuard</code> simplifient le problème :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #f8f8f2">action();</span>
<span style="color: #66d9ef">auto</span> <span style="color: #f8f8f2">sg1</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">ScopeGuard([](){</span> <span style="color: #f8f8f2">cleanup()</span> <span style="color: #f8f8f2">});</span>  <span style="color: #75715e">// en fin de scope, on cleanup</span>
<span style="color: #66d9ef">auto</span> <span style="color: #f8f8f2">sg2</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">ScopeGuard([](){</span> <span style="color: #f8f8f2">rollback()</span> <span style="color: #f8f8f2">});</span>  <span style="color: #75715e">// en fin de scope, on rollback</span>
<span style="color: #f8f8f2">next();</span>
<span style="color: #f8f8f2">sg2.dismiss();</span>  <span style="color: #75715e">// si on arrive ici, next a réussi -&gt; on annule le rollback</span>
<span style="color: #75715e">// fin du scope -&gt; on va cleanup</span></code></pre>
</div>
</div>
</li>
<li>
<p>et on peut vérifier que même si on <code>next</code> est une transaction de <code>second_action</code> et <code>second_next</code>, le code reste simple</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_href_https_www_youtube_com_watch_v_obt_vmvdm8s_understanding_the_python_gil_a_voir_aussi_le_a_href_http_dabeaz_com_gil_post_qui_va_avec_a">[VIDEO] <a href="https://www.youtube.com/watch?v=Obt-vMVdM8s">Understanding the Python GIL</a>, voir aussi le <a href="http://dabeaz.com/GIL/">post qui va avec</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_vue_le_2020_04_24_publiée_à_l_occasion_de_la_pycon_2010_le_2010_02_20_par_a_href_http_www_dabeaz_com_david_beazley_a_speaker_et_dev_python_très_influent">Vue le 2020-04-24, publiée à l&#8217;occasion de la PyCON 2010 le 2010-02-20 par <a href="http://www.dabeaz.com/">David BEAZLEY</a>, speaker et dev python très influent.</h3>
<div class="ulist">
<ul>
<li>
<p>attention, talk de 2010, deprecated (mais intéressant tout de même), il parle de python &lt; 3.2</p>
</li>
<li>
<p>présentation d&#8217;un comportement curieux, avec un calcul CPU-bound :</p>
<div class="ulist">
<ul>
<li>
<p>monothread : 5s</p>
</li>
<li>
<p>2 threads sur deux cores : 10s</p>
</li>
<li>
<p>2 threads sur un seul core : 8s</p>
</li>
<li>
<p>2 threads sur deux cores avec un process fils qui mouline en plus : 7s</p>
</li>
</ul>
</div>
</li>
<li>
<p>GIL = un seul thread avance a chaque instant.</p>
</li>
<li>
<p>ancien modèle du GIL :</p>
<div class="ulist">
<ul>
<li>
<p>GIL relâché lors des io AINSI QUE lors du "check" (si un compteur de 100 ticks=instruction de la VM arrive a zéro), pour eviter qu&#8217;un thread cpubound ne monopolise le GIL</p>
</li>
<li>
<p>Lors du check, c&#8217;est l&#8217;os qui choisit quel thread va tourner : ça peut très bien rester celui qui tournait juste avant le check</p>
</li>
<li>
<p>Ce qu&#8217;on veut éviter c&#8217;est que l&#8217;os réveille un thread à tort : le thread essaye d&#8217;acquerir le GIL sans succès puis se rendort.</p>
</li>
<li>
<p>Quand on a autant de cores que de thread, c&#8217;est EXACTEMENT ce qui se passe, du coup, BEAUCOUP de travail supplémentaire de l&#8217;os pour rien, qui empêche le thread "en cours" d&#8217;avancer, d&#8217;où les mauvaises perfs du cas 2 ci-dessus.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Nouveau GIL en python 3.2 développé par <a href="https://github.com/pitrou">Antoine PITROU</a></p>
<div class="ulist">
<ul>
<li>
<p>on n&#8217;a plus de ticks pour empêcher les threads CPU-bounds de monopoliser le GIL</p>
</li>
<li>
<p>à la place, on a une variable globale, un thread CPU-bound tourne jusque a ce que cette variable soit mise à 1</p>
</li>
<li>
<p>pas hyper clair, mais il semblerait qu&#8217;à chaque instruction, le thread checke si la var est à 1, et si oui, relâche le GIL ?!</p>
</li>
<li>
<p>un thread tourne donc indéfiniment, tant que le GIL ne lui est pas réclamé (ou, bien sûr, tant qu&#8217;il ne fait pas d&#8217;io)</p>
</li>
<li>
<p>si un deuxième thread arrive, il commence par attendre un peu (par défaut 5 ms) voir si le premier thread relâche le GIL de lui même, puis met la variable globale à 1, ce qui force le premier thread à relâcher le GIL.</p>
</li>
<li>
<p>et pour éviter que l&#8217;os ne le refasse tourner immédiatement, le thread qui vient de relâcher le GIL sleep un peu.</p>
</li>
</ul>
</div>
</li>
<li>
<p>défauts de ce modèle :</p>
<div class="ulist">
<ul>
<li>
<p>tous les threads (notamment les threads importants ou qui doivent faire de l&#8217;io) doivent purger les 5 ms avant d&#8217;agir&#8230;&#8203; manque de responsiveness</p>
</li>
<li>
<p>si beaucoup de threads, rien ne dit que c&#8217;est le thread qui a réveillé le GIL qui va être exécuté par l&#8217;os, il peut starve</p>
</li>
</ul>
</div>
</li>
<li>
<p>À noter que les io ne bloquent pas nécessairement : write bufferisé donc IO retardée, ou bien lecture depuis le page cache</p>
</li>
<li>
<p>Du coup, un thread qui fait beaucoup d&#8217;io va être TRÈS concurrencé par un autre thread cpu-bound, qui va lui piquer le GIL (et le garder! au moins le temps du timeout) à chaque io, même si cette io n&#8217;aurait pas bloqué</p>
</li>
<li>
<p>ce qui manque au nouveau GIL :</p>
<div class="ulist">
<ul>
<li>
<p>pouvoir prioriser les threads (e.g. certains threads vont rendre le GIL très vite)</p>
</li>
<li>
<p>possibilité de preempter : les threads importants (e.g. qui répondent à une requête réseau) devraient pouvoir préempter</p>
</li>
</ul>
</div>
</li>
<li>
<p>certains OS ont un mécanisme de priorisation pas mal :</p>
<div class="ulist">
<ul>
<li>
<p>si un thread a rendu la main sans être préempté, il gagne en priorité</p>
</li>
<li>
<p>à l&#8217;inverse, si un thread a dû être préempté, il perd en priorité</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_thomasvilhena_com_2019_08_a_successful_deployment_model_a_successful_deployment_model_a">[POST] <a href="https://thomasvilhena.com/2019/08/a-successful-deployment-model">A successful deployment model</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_04_13_publié_le_2019_08_02_par_a_href_https_thomasvilhena_com_thomas_vilhena_a_dev_web">Lu le 2020-04-13, publié le 2019-08-02 par <a href="https://thomasvilhena.com/">Thomas VILHENA</a> dev web.</h3>
<div class="ulist">
<ul>
<li>
<p>Selon lui, les règles pour limiter les risques liés au déploiement :</p>
<div class="ulist">
<ul>
<li>
<p>Use the same deployable image for test, staging and production environments</p>
</li>
<li>
<p>Update systems without downtime</p>
</li>
<li>
<p>Fully automate the deployment process</p>
</li>
<li>
<p>Set up and rely on automatic monitoring for early problem detection (splitté en <em>health monitoring</em> et <em>error monitoring</em>)</p>
</li>
<li>
<p>Support rollback to earlier application versions</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_robertheaton_com_2020_04_06_systems_design_for_advanced_beginners_systems_design_for_advanced_beginners_a">[POST] <a href="https://robertheaton.com/2020/04/06/systems-design-for-advanced-beginners/">Systems design for Advanced Beginners</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_04_06_publié_le_2020_04_06_par_a_href_https_robertheaton_com_about_robert_heaton_a_dev_sécurité_à_a_href_https_stripe_com_fr_stripe_société_de_paiement_en_ligne_a">Lu le 2020-04-06, publié le 2020-04-06 par <a href="https://robertheaton.com/about/">Robert HEATON</a>, dev sécurité à <a href="https://stripe.com/fr">Stripe, société de paiement en ligne</a></h3>
<div class="ulist">
<ul>
<li>
<p>une revue d&#8217;assez haut de system design pour une application web. Quelques points intéressants en vrac :</p>
<div class="ulist">
<ul>
<li>
<p>webhooks = endpoints chez les clients qu&#8217;on appelle quand on veut les avertir de quelque chose (e.g. gitlab peut appeler un webhook lorsqu&#8217;il se passe un évènement intéressant, comme un push)</p>
</li>
<li>
<p>database sharding + comment migrer</p>
</li>
<li>
<p>database replication (asynchrone vs. synchrone)</p>
</li>
<li>
<p>elasticssearch pour le full text search</p>
</li>
<li>
<p>pubsub</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_dropbox_tech_application_our_journey_to_type_checking_4_million_lines_of_python_our_journey_to_type_checking_4_million_lines_of_python_a">[POST] <a href="https://dropbox.tech/application/our-journey-to-type-checking-4-million-lines-of-python">Our journey to type checking 4 million lines of Python</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_04_01_publié_le_2019_09_05_sur_a_href_https_dropbox_tech_le_blog_tech_de_dropbox_a_utilisateur_massif_de_pythonn_par_a_href_https_twitter_com_jukkaleh_lang_fr_jukka_lehtosalo_a_auteur_initial_et_maintenant_lead_dev_de_mypy">Lu le 2020-04-01, publié le 2019-09-05 sur <a href="https://dropbox.tech/">le blog tech de Dropbox</a>, utilisateur massif de pythonn par <a href="https://twitter.com/jukkaleh?lang=fr">Jukka LEHTOSALO</a>, auteur initial et maintenant lead dev de mypy.</h3>
<div class="ulist">
<ul>
<li>
<p>L&#8217;intéressante histoire de mypy racontée par son créateur.</p>
</li>
<li>
<p>On suit l&#8217;outil depuis ses débuts sur un langage de recherche (Alore) jusqu&#8217;à python, en passant par la rencontre avec Guido VAN ROSSUM, <a href="https://www.python.org/dev/peps/pep-0484/">la standardisation du type-hinting</a> l&#8217;adoption massive au sein de Dropbox, et les résolutions des problèmes liées aux performances.</p>
</li>
<li>
<p>Au final, au sein de Dropbox, 4 millions de LOC sont type-checkées.</p>
</li>
<li>
<p>Un REX intéressant est la façon dont ils ont atteint ce chiffre, en cumulant plusieurs stratégies :</p>
<div class="ulist">
<ul>
<li>
<p>forcer les type-annotations pour les nouveaux fichiers de code</p>
</li>
<li>
<p>produire toutes les semaines un rapport sur la couverture de code</p>
</li>
<li>
<p>sensibilisation des équipes</p>
</li>
<li>
<p>prendre le retour des utilisateurs</p>
</li>
<li>
<p>améliorer les perfs pour faciliter l&#8217;adoption</p>
</li>
<li>
<p>ajouter des outils pour les IDE populaires</p>
</li>
<li>
<p>outils d&#8217;analyse statique</p>
</li>
<li>
<p><a href="https://www.python.org/dev/peps/pep-0561/">stub-files</a> pour des librairies tierces</p>
</li>
</ul>
</div>
</li>
<li>
<p>L&#8217;une des difficultés a été la gestion des imports cycliques.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_href_https_youtu_be_oq5jsbhav_m_19_dynamic_programming_i_fibonacci_shortest_paths_a">[VIDEO] <a href="https://youtu.be/OQ5jsbhAv_M">19. Dynamic Programming I: Fibonacci, Shortest Paths</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_visionnée_le_2020_04_01_publiée_le_2013_01_14_sur_a_href_https_www_youtube_com_channel_ucebb1b_l6zds3xturialzow_la_chaîne_mit_opencourseware_a_présenté_par_a_href_https_en_wikipedia_org_wiki_erik_demaine_erik_demaine_a_qui_a_l_air_d_être_une_star_entre_autre_licence_à_14_ans_professeur_au_mit_à_20_ans_la_vidéo_fait_partie_de_la_série_de_cours_a_href_https_ocw_mit_edu_courses_electrical_engineering_and_computer_science_6_006_introduction_to_algorithms_fall_2011_introduction_to_algorithms_a">Visionnée le 2020-04-01, publiée le 2013-01-14 sur <a href="https://www.youtube.com/channel/UCEBb1b_L6zDS3xTUrIALZOw">la chaîne MIT OpenCourseWare</a>, présenté par <a href="https://en.wikipedia.org/wiki/Erik_Demaine">Erik DEMAINE</a>, qui a l&#8217;air d&#8217;être une star (entre autre : licence à 14 ans, professeur au MIT à 20 ans). La vidéo fait partie de la série de cours <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-006-introduction-to-algorithms-fall-2011/">Introduction to Algorithms</a>.</h3>
<div class="sect3">
<h4 id="_principe">Principe</h4>
<div class="ulist">
<ul>
<li>
<p>programmation dynamique (= dynamic programming = DP) = explorer exhaustivement et récursivement toutes les solutions + memoization</p>
</li>
<li>
<p>exemple très didactique qui sert de fil-rouge : calcul du n-ième terme de la suite de Fibonacci</p>
</li>
<li>
<p>la DP est utile lorsqu&#8217;on cherche à résoudre un problème d&#8217;optimisation : trouver le min, le max, le "plus court", etc.</p>
</li>
<li>
<p>principe = découper le problème en sous-problèmes qui aident à résoudre le problème principal &#8594; l&#8217;un des challenges de la DP c&#8217;est d&#8217;identifier les sous-problèmes</p>
</li>
<li>
<p>les sous-problèmes peuvent être d&#8217;une nature DIFFÉRENTE du problème initial (même si ce n&#8217;est pas le cas pour le fil rouge, où les sous-problèmes sont identiques au problème principal)</p>
</li>
<li>
<p>memoization = lorsqu&#8217;on a déjà résolu l&#8217;un des sous-problèmes, on n&#8217;a plus besoin de le refaire (tiens, j&#8217;apprends l&#8217;origine du terme : "memoize something" c&#8217;est "le transformer en memo")</p>
</li>
<li>
<p>terminologie : à l&#8217;époque, le terme "programmation" signifie "ordonnancement" &#8594; DP = ordonnancement dynamique</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_approche_top_down_vs_bottom_up">Approche top-down vs. bottom-up</h4>
<div class="paragraph">
<p>Deux façons d&#8217;approcher un problème en programmation dynamique :</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>TOP-DOWN</strong> : on part du problème final, et on le décompose récursivement en les sous-problèmes. Cette approche correspond au problème, mais il faut réfléchir un peu pour savoir ce qui est memoizé.</p>
<div class="ulist">
<ul>
<li>
<p>Exemple du fil rouge : quand on visualise l&#8217;arbre binaire des Fn, on part du top (le calcul de <code>F(n)</code>) et on descend, en calculant les termes suivants (<code>F(n-1)</code>, <code>F(n-2)</code>) pour finir par les racines (<code>F0</code>, <code>F1</code>) :</p>
<div class="imageblock text-center">
<div class="content">
<img src="../notes-img/dynamicprogrammation/fibonacci_binary_tree_topdown.svg" alt="fibonacci binary tree topdown">
</div>
<div class="title">Figure 1. Approche top-down</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="python"><span style="color: #66d9ef">def</span> <span style="color: #a6e22e">fib</span><span style="color: #f8f8f2">(n:</span> <span style="color: #f8f8f2">int)</span> <span style="color: #f92672">-&gt;</span> <span style="color: #f8f8f2">int:</span>
    <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">n</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">0</span><span style="color: #f8f8f2">:</span>
        <span style="color: #66d9ef">return</span> <span style="color: #ae81ff">0</span>
    <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">n</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">:</span>
        <span style="color: #66d9ef">return</span> <span style="color: #ae81ff">1</span>
    <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">n</span> <span style="color: #f92672">not</span> <span style="color: #f92672">in</span> <span style="color: #f8f8f2">memo:</span>
        <span style="color: #75715e"># on part de fib(n) et on &quot;descend&quot; l&#39;arbre vers fib(n-1) et fib(n-2) :</span>
        <span style="color: #f8f8f2">memo[n]</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">fib(n</span><span style="color: #f92672">-</span><span style="color: #ae81ff">2</span><span style="color: #f8f8f2">)</span> <span style="color: #f92672">+</span> <span style="color: #f8f8f2">fib(n</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">)</span>
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">memo[n]</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p><strong>BOTTOM-UP</strong> : en partant de zéro, on construit ce dont on aura besoin, en terminant par le problème final. Exemple du fil rouge : quand on visualise l&#8217;arbre binaire des Fn, on calcule successivemnt tous les termes en partant du bas de l&#8217;arbre (<code>F(0)</code>, <code>F(1)</code>, &#8230;&#8203;) pour finir par exprimer la solution au problème final en utilisant les éléments calculés jusque-là.</p>
<div class="ulist">
<ul>
<li>
<p>Dans le diagramme suivant, seuls les noeuds coloriés en rose sont effectivement calculés et mémoizés : les autres noeuds ont <em>déjà</em> été calclés, et sont donc simplement récupérés dans le mémo.</p>
<div class="imageblock text-center">
<div class="content">
<img src="../notes-img/dynamicprogrammation/fibonacci_binary_tree_bottomup.svg" alt="fibonacci binary tree bottomup">
</div>
<div class="title">Figure 2. Approche bottom-up</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="python"><span style="color: #66d9ef">def</span> <span style="color: #a6e22e">fib</span><span style="color: #f8f8f2">(n:</span> <span style="color: #f8f8f2">int)</span> <span style="color: #f92672">-&gt;</span> <span style="color: #f8f8f2">int:</span>
    <span style="color: #f8f8f2">memo</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">dict()</span>
    <span style="color: #75715e"># on itère sur tous les sous-problèmes en commençant par le &quot;bottom&quot; de l&#39;arbre</span>
    <span style="color: #66d9ef">for</span> <span style="color: #f8f8f2">i</span> <span style="color: #f92672">in</span> <span style="color: #f8f8f2">range(n):</span>
        <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">i</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">0</span><span style="color: #f8f8f2">:</span>
            <span style="color: #f8f8f2">memo[i]</span> <span style="color: #f92672">=</span> <span style="color: #ae81ff">0</span>
        <span style="color: #66d9ef">elif</span> <span style="color: #f8f8f2">i</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">:</span>
            <span style="color: #f8f8f2">memo[i]</span> <span style="color: #f92672">=</span> <span style="color: #ae81ff">1</span>
        <span style="color: #66d9ef">else</span><span style="color: #f8f8f2">:</span>
            <span style="color: #f8f8f2">memo[i]</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">memo[i</span><span style="color: #f92672">-</span><span style="color: #ae81ff">2</span><span style="color: #f8f8f2">]</span> <span style="color: #f92672">+</span> <span style="color: #f8f8f2">memo[i</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">]</span>
    <span style="color: #75715e"># le problème final s&#39;exprime naturellement en fonction des sous-problèmes résolus jusqu&#39;ici :</span>
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">memo[n</span><span style="color: #f92672">-</span><span style="color: #ae81ff">2</span><span style="color: #f8f8f2">]</span> <span style="color: #f92672">+</span> <span style="color: #f8f8f2">memo[n</span><span style="color: #f92672">-</span><span style="color: #ae81ff">1</span><span style="color: #f8f8f2">]</span></code></pre>
</div>
</div>
</li>
<li>
<p>à noter que l&#8217;approche bottom-up est un tri topologique du DAG des sous-problèmes. Pour le fil rouge de Fibonacci, le DAG est simplement chaque Fn qui dépend de Fn-1 et Fn-2 :</p>
<div class="imageblock text-center">
<div class="content">
<img src="../notes-img/dynamicprogrammation/dependencies_dag.svg" alt="dependencies dag">
</div>
<div class="title">Figure 3. DAG des dépendances pour Fibonacci</div>
</div>
</li>
<li>
<p>par ailleurs, l&#8217;approche bottom-up peut parfois permettre d&#8217;être plus efficace en espace (e.g. avec le fil rouge fib, dans l&#8217;approche bottom-up, on pourrait se contenter de garder les deux dernières valeurs de fib, et jeter les autres)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_reste_des_notes">Reste des notes</h4>
<div class="ulist">
<ul>
<li>
<p>autre exemple donné avec le calcul d&#8217;un plus court chemin dans un graphe : l&#8217;approche par programmation dynamique aboutit à l&#8217;algorithme de Bellman-Ford</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Dynamic_programming">page wikipedia sur la programmation dynamique</a> = trois catégorisation d&#8217;un problème en fonction des sous-problèmes :</p>
<div class="ulist">
<ul>
<li>
<p>doesn&#8217;t have <em>optimal substructure</em> : on ne peut pas résoudre un problème en résolvant ses sous-problèmes. Exemple = le prix d&#8217;un billet d&#8217;avion <em>Paris&#8594;Heathrow&#8594;New-York</em> <strong>N&#8217;EST PAS</strong> la somme du prix de <em>Paris&#8594;Heathrow</em> et de <em>Heathrow&#8594;New-York</em>.</p>
</li>
<li>
<p>has <em>optimal substructure</em>, et les sous-problèmes sont indépendants : on peut résoudre ces problèmes par une approche <a href="https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm">divide and conquer</a>. Exemple = merge sort.</p>
</li>
<li>
<p>has <em>optimal substructure</em>, et les sous-problèmes se recouvrent : on peut résoudre ces problèmes par une approche de programmation dynamique. Exemple = calcul du n-ième terme de la suite de Fibonacci, <a href="https://fr.wikipedia.org/wiki/Programmation_dynamique#Pyramide_de_nombres">descente d&#8217;une pyramide de nombre maximisant la somme</a>.</p>
</li>
</ul>
</div>
</li>
<li>
<p>complexité algorithmique en DP = nombre de sous-problèmes * complexité de chaque sous-problème</p>
<div class="ulist">
<ul>
<li>
<p>exemple pour fib : chaque sous-problème a un temps constant (vu que c&#8217;est la somme de deux entiers déjà calculés)</p>
</li>
<li>
<p>il y en a N (pour calculer fib(n), il vaut avoir calculé les N-1 fib)</p>
</li>
<li>
<p>-&#8594; complexité de l&#8217;algo DP pour calculer fib = linéaire</p>
</li>
</ul>
</div>
</li>
<li>
<p>pour que la DP soit possible : les dépendances des sous-problèmes doivent être un DAG : s&#8217;il y a un cycle, il n&#8217;y aura pas d&#8217;ordre (tri topologique) selon lequel résoudre les sous-problèmes.</p>
<div class="ulist">
<ul>
<li>
<p>une astuce futée pour les calculs dans les graphes (alors même que le graphe lui-même est cyclique !) c&#8217;est de les représenter comme évoluant avec le temps. Ainsi, le graphe cyclique suivant :</p>
<div class="imageblock text-center">
<div class="content">
<img src="../notes-img/dynamicprogrammation/from_cyclic_graph.svg" alt="from cyclic graph">
</div>
<div class="title">Figure 4. Graphe cyclique</div>
</div>
</li>
<li>
<p>Pourra être représenté par une série de graphes successifs évoluant avec le temps, ce qui brise les cycles :</p>
<div class="imageblock text-center">
<div class="content">
<img src="../notes-img/dynamicprogrammation/to_acyclic_graph.svg" alt="to acyclic graph">
</div>
<div class="title">Figure 5. Le même graphe rendu acyclique</div>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_robbertkrebbers_nl_research_articles_safe_programming_rust_pdf_safe_systems_programming_in_rust_the_promise_and_the_challenge_a">[ARTICLE] <a href="https://robbertkrebbers.nl/research/articles/safe_programming_rust.pdf">Safe Systems Programming in Rust:The Promise and the Challenge</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_03_publié_le_2020_article_en_cours_de_soumission_par_a_href_https_robbertkrebbers_nl_robbert_krebbers_a_assistant_professor_in_the_programming_languages_group_at_the_department_of_software_technology_at_delft_university_of_technology_ainsi_que_ralf_jung_jacques_henri_jourdan_et_derek_dreyer">Lu le 2020-03-??, publié le 2020-??-?? (article en cours de soumission) par <a href="https://robbertkrebbers.nl/">Robbert KREBBERS</a> assistant professor in the programming languages group at the department of software technology at Delft University of Technology, ainsi que Ralf JUNG, Jacques-Henri JOURDAN, et Derek DREYER.</h3>
<div class="ulist">
<ul>
<li>
<p>très bon article (très détaillé) sur rust et son borrow checker</p>
</li>
<li>
<p>quelques mots qui ne lui rendent pas justice : pourquoi rust est safe ?</p>
<div class="ulist">
<ul>
<li>
<p>Interdit d&#8217;avoir de l&#8217;aliasing (i.e. deux pointeurs différents qui pointent vers la même zone mémoire) à moins qu&#8217;un seul des pointeurs aie les droits d&#8217;écriture</p>
</li>
<li>
<p>Borrow checker = seule une référence à la fois a le droit de muter (donc éventuellement détruire ou invalider) un objet</p>
</li>
<li>
<p>Dit autrement, une référence peut autoriser l&#8217;aliasing ou la mutabilité mais pas les deux en même temps</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_amy_dev_p_783_my_coding_interview_style_a">[POST] <a href="https://amy.dev/?p=783">My Coding Interview Style</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_03_11_publié_le_2017_12_04_par_a_href_https_amy_dev_amy_nguyen_a_dev_d_api_de_paiement_à_a_href_https_stripe_com_fr_stripe_société_de_paiement_en_ligne_a">Lu le 2020-03-11, publié le 2017-12-04 par <a href="https://amy.dev/">Amy NGUYEN</a>, dev d&#8217;API de paiement à <a href="https://stripe.com/fr">Stripe, société de paiement en ligne</a></h3>
<div class="ulist">
<ul>
<li>
<p>Une revue du sprocess qu&#8217;elle suit à chaque fois qu&#8217;elle passe un coding interview.</p>
</li>
<li>
<p>L&#8217;article est court mais concret, ne pas hésiter à le relire.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_id_video_sur_p_egal_np_a_a_href_https_www_youtube_com_watch_v_yx40hbahx3s_p_vs_np_et_le_zoo_de_complexité_informatique_a">[VIDEO] <a id="video-sur-P-egal-NP"></a><a href="https://www.youtube.com/watch?v=YX40hbAHx3s">P vs NP et le zoo de complexité informatique</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_visionnée_le_2020_03_10_publié_le_2014_08_26_par_a_href_https_www_youtube_com_channel_ucxbws0tpcllxp2uv2x30ofq_hackerdashery_a_un_a_href_http_www_hackerdashery_com_blog_tech_a">Visionnée le 2020-03-10, publié le 2014-08-26 par <a href="https://www.youtube.com/channel/UCxBws0tpClLXp2Uv2x30OFQ">hackerdashery</a>, un <a href="http://www.hackerdashery.com/">blog tech ?</a></h3>
<div class="ulist">
<ul>
<li>
<p>Différentes classes de problèmes :</p>
<div class="ulist">
<ul>
<li>
<p><strong>problèmes de classe P</strong> = étant donné un problème, on dispose d&#8217;un algo pour le résoudre "facilement", i.e. en trouver la solution.</p>
<div class="ulist">
<ul>
<li>
<p>Exemple concret = trouver le plus court chemin dans un graphe</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>problèmes de classe NP</strong> = étant donnée une solution supposée, on sait dire "facilement" si c&#8217;est bien une solution ou pas.</p>
<div class="ulist">
<ul>
<li>
<p>Exemple concret = si tu me donnes comme problème une grille de départ (incomplète) de Sudoku, et comme solution supposée la même grille remplie, je sais dire facilement si la grille remplie est bien une solution valide de la grille de départ. Pour autant, je n&#8217;ai pas d&#8217;algo efficace pour trouver une solution à la grille de départ.</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>problème non-NP</strong> = étant donnée une solution supposée, on ne sait même pas dire "facilement" si c&#8217;est bien une solution ou pas.</p>
<div class="ulist">
<ul>
<li>
<p>Exemple concret = si tu me donnes comme problème une situation de jeu d&#8217;échecs donnée où il faut que je trouve le meilleur prochain coup, et comme solution supposée un coup X, je ne peux même dire facilement si X est bien le meilleur prochain coup ou non.</p>
</li>
</ul>
</div>
</li>
<li>
<p>on sait résoudre "facilement" signifie on peut trouver une solution en un nombre de steps polynomial par rapport à la "taille" du problème</p>
</li>
</ul>
</div>
</li>
<li>
<p>question : <strong>est-ce que <code>P == NP</code></strong> ? C&#8217;est l&#8217;un des <a href="https://fr.wikipedia.org/wiki/Probl%C3%A8mes_du_prix_du_mill%C3%A9naire#Probl%C3%A8me_ouvert_P_=_NP">7 problèmes du prix du millénaire</a>, on conjecture sans pouvoir le prouver que <code>P != NP</code></p>
</li>
<li>
<p>à noter que NP contient P : en effet, si on sait déjà trouver la solution à un problème facilement, on saura aussi évaluer si une proposition donnée en est une solution (il suffit de trouver la solution, et de la comparer à la proposition)</p>
</li>
<li>
<p>ce qui nous intéresse, c&#8217;est le pire cas, lorsqu&#8217;on fait grossir la "taille" du problème :</p>
<div class="ulist">
<ul>
<li>
<p>(NP) résoudre un petit sudoku est facile  vs. (P) multiplier deux petits nombres est facile</p>
</li>
<li>
<p>(NP) résoudre un très grand sudoku est impossible  vs.  (P) multiplier deux très grands nombre est certes moins trivial, mais reste facile</p>
</li>
<li>
<p>dit autrement : comment la difficulté du problème évolue lorsque la "taille" du problème augmente ?</p>
<div class="ulist">
<ul>
<li>
<p>"taille" pour la multiplication = p.ex. nombre de digits dans les nombres</p>
</li>
<li>
<p>"taille" pour le sudoku = p.ex. largeur de la grille</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>il y a BEAUCOUP de classes de complexité :</p>
<div class="ulist">
<ul>
<li>
<p>lorsqu&#8217;on nous donne une proposition de solution, on ne sait même pas dire si elle est bonne (non-NP, du coup)</p>
</li>
<li>
<p>peut être facile en temps mais pas en espace, et vice versa</p>
</li>
<li>
<p>peut être exponentiel, probabiliste, dépendre d&#8217;un ordinateur quantique, etc.</p>
</li>
</ul>
</div>
</li>
<li>
<p>un point rigolo : la crypto repose sur le fait que <code>P != NP</code> (en effet, étant donné une clé, on sait dire si c&#8217;est la clé qui a servi à chiffrer le message ou pas &#8594; NP, mais on ne sait pas trouver facilement la clé &#8594; pas P)</p>
</li>
<li>
<p>Si <code>P == NP</code>, ça veut dire que "le fait d&#8217;être capable de RECONNAÎTRE une solution à un problème signifie qu&#8217;on est aussi capable de la TROUVER à partir de rien)</p>
</li>
<li>
<p>Exemples de problèmes NP-difficiles = voyageur de commerce, problème du sac-à-dos, etc.</p>
</li>
</ul>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>En pratique, les informaticiens et les développeurs sont souvent confrontés à des problèmes NP-complets.</p>
</div>
<div class="paragraph">
<p>Dans ce cas, savoir que le problème sur lequel on travaille est NP-complet est une indication du fait que le problème est difficile à résoudre, donc qu&#8217;il vaut mieux chercher des solutions approchées en utilisant des algorithmes d&#8217;approximation ou utiliser des heuristiques pour trouver des solutions exactes.</p>
</div>
</blockquote>
<div class="attribution">
&#8212; <a href="https://fr.wikipedia.org/wiki/Probl%C3%A8me_NP-complet">Problème NP-complet sur wikipedia</a>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_http_www_stroustrup_com_resource_model_pdf_a_brief_introduction_to_c_s_model_for_type_and_resource_safety_a">[ARTICLE] <a href="http://www.stroustrup.com/resource-model.pdf">A brief introduction to C++’s model for type- and resource-safety</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_03_08_publié_le_2015_12_par_bjarne_stroustrup_morgan_stanley_herb_sutter_microsoft_gabriel_dos_reis_microsoft_aussi_a_participé_au_dévelopemment_des_modules">Lu le 2020-03-08, publié le 2015-12-?? par Bjarne STROUSTRUP (Morgan Stanley), Herb SUTTER (Microsoft), Gabriel DOS REIS (Microsoft aussi, a participé au dévelopemment des modules)</h3>
<div class="ulist">
<ul>
<li>
<p>propositions pour plus de type-safety et resource-safety (= non-leaking resource management), contraintes = zero-overhead principle + rétrocompatible</p>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>We say that a program is memory safe if every allocated object is deallocated (once only) and no access is done through a pointer (or reference, iterator, or other non-owning indirection) to an object that has been deleted or gone out of scope (and thus technically isn’t an object any more – just a bag of bits).</p>
</div>
<div class="paragraph">
<p>To be type safe, we need memory safety so that an object cannot be accessed through a dangling pointer</p>
</div>
<div class="paragraph">
<p>[...]</p>
</div>
<div class="paragraph">
<p>Furthermore, to be perfectly type safe, a program must be free of range errors (access beyond the end of an array), free of access through the null pointer, etc.</p>
</div>
</blockquote>
</div>
</li>
<li>
<p>TL;DR : suggestions =</p>
<div class="ulist">
<ul>
<li>
<p>type system avec une abstraction pour l&#8217;ownership</p>
</li>
<li>
<p>lib de support (GSL)</p>
</li>
<li>
<p>analyse statique pour enforce les rules</p>
</li>
</ul>
</div>
</li>
<li>
<p>revue rapide des erreurs liées à la mémoire :</p>
<div class="ulist">
<ul>
<li>
<p>resource leak (= si un objet n&#8217;est pas détruit)</p>
</li>
<li>
<p>accesss through an invalid pointer</p>
</li>
<li>
<p>memory corruption (= on peut écrire des données d&#8217;un type T1 sur une zone mémoire qui est d&#8217;un type T2 &#8594; on corrompt T2)</p>
</li>
<li>
<p>confusion statique (pas besoin de delete) / dynamique (besoin de delete)</p>
</li>
<li>
<p>use after free / out of range access / null pointer</p>
</li>
</ul>
</div>
</li>
<li>
<p>Non-retenu = modèle dynamique :</p>
<div class="ulist">
<ul>
<li>
<p>what = bit encodant l&#8217;ownership dans les LSB de l&#8217;adresse pointée par le pointeur</p>
</li>
<li>
<p>deux pointeurs "identiques" peuvent être owner ou non-owner :</p>
<div class="ulist">
<ul>
<li>
<p>si on a obtenu le pointeur par new, le pointeur est owner, sinon, le pointeur est non-owner</p>
</li>
<li>
<p>si un owner pointeur goes out of scope (ou est overwritten), on delete la zone mémoire</p>
</li>
<li>
<p>on peut se transmettre l&#8217;ownership</p>
</li>
</ul>
</div>
</li>
<li>
<p>(du peu que j&#8217;en connais, ça ressemble au borrowing de rust ?)</p>
</li>
<li>
<p>non-retenu car :</p>
<div class="ulist">
<ul>
<li>
<p>augmente la taille mémoire du pointeur (ou bien utilise des bits "cachés" qui dépendent de l&#8217;alignement)</p>
</li>
<li>
<p>augmente la complexité de manipulation des adresses mémoires (e.g. arithmétique des pointeurs)</p>
</li>
<li>
<p>pas rétro-compatible</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Retenu = modèle statique :</p>
<div class="ulist">
<ul>
<li>
<p>what = au lieu d&#8217;utiliser <code>T*,</code> on utiliser <code>owner&lt;T*&gt;</code> pour marquer l&#8217;ownership</p>
</li>
<li>
<p>pour rester ABI-compatible, <code>owner&lt;T*&gt;</code> est un alias vers <code>T*</code> (c&#8217;est ça qui est fourni par GSL)</p>
</li>
<li>
<p>ce marquage par owner NE FAIT RIEN, il permet surtout l&#8217;analyse statique</p>
</li>
<li>
<p>recommandation = quand c&#8217;est possible, utiliser plutôt les classes d&#8217;ownership (i.e. les resource-handlers) faîtes pour ça (e.g. vector, unique_ptr)</p>
</li>
<li>
<p>c&#8217;est pas rose non plus, il y a des limitations</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_stackoverflow_blog_2020_03_05_a_modern_hello_world_program_needs_more_than_just_code_a_modern_hello_world_program_needs_more_than_just_code_a">[POST] <a href="https://stackoverflow.blog/2020/03/05/a-modern-hello-world-program-needs-more-than-just-code/">A modern ‘Hello, World’ program needs more than just code</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_03_06_publié_le_2020_03_05_par_charles_r_martin_sur_a_href_https_stackoverflow_blog_le_blog_de_stackoverflow_a">Lu le 2020-03-06, publié le 2020-03-05 par Charles R. MARTIN, sur <a href="https://stackoverflow.blog">le blog de StackOverflow</a></h3>
<div class="ulist">
<ul>
<li>
<p>le point principal de l&#8217;article, c&#8217;est que <code>Hello world</code> ne sert pas à réussir à afficher une chaîne à l&#8217;écran, mais à bootstrapper un projet :</p>
<div class="ulist">
<ul>
<li>
<p>créer le code source dans un fichier quelque part</p>
</li>
<li>
<p>le compiler/linker</p>
</li>
<li>
<p>l&#8217;exécuter</p>
</li>
<li>
<p>trouver où il a produit sa sortie</p>
</li>
</ul>
</div>
</li>
<li>
<p>de nos jours, un <code>Hello world</code> adapté est donc plutôt :</p>
<div class="ulist">
<ul>
<li>
<p>disposer du repo et savoir commiter/pusher</p>
</li>
<li>
<p>avoir choisi son IDE/ses outils</p>
</li>
<li>
<p>savoir builder le process</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__article_a_href_https_www_research_ed_ac_uk_portal_files_78829292_low_cost_deterministic_c_exceptions_for_embedded_systems_pdf_low_cost_deterministic_c_exceptions_for_embedded_systems_a">[ARTICLE] <a href="https://www.research.ed.ac.uk/portal/files/78829292/low_cost_deterministic_C_exceptions_for_embedded_systems.pdf">Low-Cost Deterministic C++ Exceptions for Embedded Systems</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_03_04_publié_le_2019_par_james_renwick_tom_spink_et_björn_franke_chercheurs_de_l_université_d_edinburgh">Lu le 2020-03-04, publié le 2019-??-?? par James RENWICK, Tom SPINK et Björn FRANKE, chercheurs de l&#8217;université d&#8217;Edinburgh.</h3>
<div class="ulist">
<ul>
<li>
<p>implémentation actuelle des exceptions = gratuit si pas de throw, mais coûteux si throw</p>
</li>
<li>
<p>mais surtout : gros volumes de binaires + imprédictibilité de l&#8217;utilisation des ressources</p>
</li>
<li>
<p>en embarqué :</p>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>for use in embedded systems, where binary size and determinism are often as, if not more, important than overall execution time</p>
</div>
</blockquote>
</div>
</li>
<li>
<p>suggestion = <code>status</code> (throw ou pas) stocké sur la stack, et le mécanisme d&#8217;exception maintient le statut</p>
</li>
<li>
<p>en assembleur, les fonctions retournent classiquement, puis on vérifie si le <code>status</code> est exceptionnel (et si oui, goto le catch handler)</p>
</li>
<li>
<p>le throw est équivalent à un set du <code>status</code> + return</p>
</li>
<li>
<p>à la différence de l&#8217;implémentation standard des exceptions, la proposition a un petit coût au runtime (même en l&#8217;absence de throw) à cause du check du <code>status</code> systématique après un call</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__site_a_href_https_benchmarksgame_team_pages_debian_net_benchmarksgame_the_computer_language_benchmarks_game_a">[SITE] <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/">The Computer Language Benchmarks Game</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_26_publié_le_par_debian">Lu le 2020-02-26, publié le ????-??-?? par Debian</h3>
<div class="ulist">
<ul>
<li>
<p>des résultats de benchmarks sur divers programmes (mandelbrot, binary-trees, digits de pi, etc.), systématiquement sourcés, pour les langages principaux</p>
</li>
<li>
<p>pour chaque langage, il y a des comparaisons avec d&#8217;autres langages, <a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/go-gpp.html">e.g. go vs C&#43;&#43;</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__video_a_href_https_www_youtube_com_watch_v_3lrmi5nodxu_l_api_management_au_delà_des_promesses_a">[VIDEO] <a href="https://www.youtube.com/watch?v=3Lrmi5NOdxU">L&#8217;API Management : au-delà des promesses</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_vidéo_vue_le_2020_02_26_publié_le_2020_02_03_par_adrien_graux_daniel_sabin_dans_le_cadre_de_a_href_https_www_laduckconf_com_la_duckconf_a_conférence_tech_d_octo">Vidéo vue le 2020-02-26, publié le 2020-02-03 par Adrien GRAUX &amp; Daniel SABIN dans le cadre de <a href="https://www.laduckconf.com/">la DuckConf</a>, conférence tech d&#8217;OCTO</h3>
<div class="ulist">
<ul>
<li>
<p>TL;DR : attention, tout n&#8217;est pas rose avec les API managers, surtout si on sort des cas bateaux</p>
</li>
<li>
<p>notamment pour la sécurité, on se retrouve à coder des choses soi-même</p>
</li>
<li>
<p>mais également pour le monitoring (ils se retrouve à brancher du ElasticSearch + kibana sur les logs de la gateway)</p>
</li>
<li>
<p>ou le portail développeur (ils se retrouvent à le recoder pour avoir qqch de différenciant)</p>
</li>
<li>
<p>point de vigilance = l&#8217;organisation des équipes et des modèles pour scaler et industrialiser la consommation d&#8217;API</p>
</li>
<li>
<p>organisation suggérée = squad API : une équipe transverse maintient le tool, et chaque équipe est autonome dans sa publication d&#8217;API</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_cor3ntin_github_io_posts_abi_the_day_the_standard_library_died_a">[POST] <a href="https://cor3ntin.github.io/posts/abi/">The Day The Standard Library Died</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_25_publié_le_2020_02_24_sur_a_href_https_cor3ntin_github_io_class_bare_https_cor3ntin_github_io_a_le_blog_de_a_href_https_www_linkedin_com_in_corentin_jabot_190b9749_corentin_jabot_a_dev_c_bordelais">Lu le 2020-02-25, publié le 2020-02-24 sur <a href="https://cor3ntin.github.io/" class="bare">https://cor3ntin.github.io/</a>, le blog de <a href="https://www.linkedin.com/in/corentin-jabot-190b9749/">Corentin JABOT</a>, dev C++ bordelais.</h3>
<div class="ulist">
<ul>
<li>
<p>TL;DR : un point de vue intéressant mais pessimiste sur la décision du comité C++ de ne pas casser l&#8217;ABI-compatibility dans un futur proche.</p>
</li>
<li>
<p>le comité à choisi de ne pas casser l&#8217;ABI du C dans C23, mais dans un futur non déterminé</p>
</li>
<li>
<p>pourtant, casser l&#8217;ABI a des avantages, parmi lesquels rendre les conteneurs associatifs plus efficaces.</p>
</li>
<li>
<p>mais surtout : le fait de NE PAS casser l&#8217;ABI a des inconvénients : lourd en terme de design, rend les futurs modules moins intéressants, empêche de meilleurs implémentations des exceptions, etc.</p>
</li>
<li>
<p>problème : si on refuse de le faire maintenant, rien ne dit que ce sera plus facile plus tard !</p>
</li>
<li>
<p>pose une question importante : <em>What is C++ and what is the standard library?</em>. Si on répond <em>performance</em>, <em>zero-cost abstractions</em> ou  <em>don’t pay for what you don’t use</em>, on ne PEUT PAS répondre en même temps "ABI stability".</p>
</li>
<li>
<p>extrait : <em>No you shouldn’t link against apt-installed c++ system libraries (which are intended for the system)</em></p>
</li>
<li>
<p>extrait : <em>The estimated performance loss due to our unwillingness to break ABI is estimated to be 5-10%</em> &#8594; du coup, pas mal d&#8217;initiatives pour shunter la lib standard : EASTL, folly, abseil, &#8230;&#8203;</p>
</li>
<li>
<p>parmi d&#8217;autres non annotées ici, une proposition intéressante (mais pas possible en pratique car ajoute une indirection + oblige la heap-allocation) est : <em>One solution to some ABI issues could be to access the data of a type trough a pointer such that the layout of a type would only be that pointer. This corresponds roughly to the PIMPL idiom which is used extensively in Qt for ABI reasons.</em></p>
</li>
<li>
<p>extrait : <em>Many believe that the committee could simply not make that decision because implementers would simply ignore the committee.</em></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_danluu_com_monorepo_advantages_of_monorepos_a">[POST] <a href="https://danluu.com/monorepo/">Advantages of monorepos</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_26_publié_le_2009_07_19_par_a_href_https_github_com_danluu_dan_luu_a_qui_fait_de_la_vulgarisation_informatique_sur_des_sujets_assez_bas_niveaux">Lu le 2020-02-26, publié le 2009-07-19 par <a href="https://github.com/danluu">Dan LUU</a>, qui fait de la vulgarisation informatique sur des sujets assez bas-niveaux</h3>
<div class="ulist">
<ul>
<li>
<p>l&#8217;article liste les intérêts du monorepo (sans revenir particulièrement sur les inconvénients)</p>
</li>
<li>
<p>le plus gros avantage (qui revient quasiment pour tous les points, même s&#8217;ils sont censés adresser des questions différentes) : ça simplifie la gestion des dépendances :</p>
<div class="ulist">
<ul>
<li>
<p>With multiple repos, you need to have some way of specifying and versioning dependencies between them.</p>
</li>
<li>
<p>With a monorepo, it&#8217;s easy to have one universal version number for all projects.</p>
</li>
<li>
<p>Using a monorepo where HEAD always points to a consistent and valid version removes the problem of tracking multiple repo versions entirely.</p>
</li>
</ul>
</div>
</li>
<li>
<p>l&#8217;organisation des fichiers / répertoires n&#8217;est plus dictée par les contraintes liées au fait d&#8217;avoir plusieurs repos : on organise les choses comme on veut.</p>
</li>
<li>
<p>tooling plus simple : analyse statique, tests d&#8217;intégration, grep du code, etc : tout ça est plus facile si tout est dans un seul repo.</p>
</li>
<li>
<p>les modifs qui auraient impacté plusieurs repos sont plus facile : with a monorepo, you just refactor the API and all of its callers in one commit.</p>
</li>
<li>
<p>analogie avec la transition [svn&#8594;git] :</p>
<div class="ulist">
<ul>
<li>
<p>svn (=un commit modifie un fichier) &#8594; git (=un commit modifie plusieurs fichiers)</p>
</li>
<li>
<p>monorepo (= un commit modifie un repo) &#8594; multirepo (= un commit modifie plusieurs repos)</p>
</li>
</ul>
</div>
</li>
<li>
<p>modèle utilisé par des grands donc solide : Google, Facebook, Twitter, Digital Ocean, and Etsy</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__site_a_href_https_yosefk_com_c_fqa_fqa_html_c_frequently_questioned_answers_a">[SITE] <a href="https://yosefk.com/c++fqa/fqa.html">C&#43;&#43; Frequently Questioned Answers</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_24_publié_le_20_par_a_href_https_yosefk_com_yossi_kreinin_a_dev_plutôt_bas_niveau_hardware_compilers_dans_le_domaine_de_la_sécurité_et_des_voitures_autonomes">Lu le 2020-02-24, publié le 20??-??-?? par <a href="https://yosefk.com/">Yossi KREININ</a>, dev plutôt bas-niveau (hardware / compilers) dans le domaine de la sécurité, et des voitures autonomes.</h3>
<div class="ulist">
<ul>
<li>
<p>La première partie est une revue détaillée très intéressante (quoique très biaisée) des défauts du C++, les critiques sont argumentées et souvent avec des exemples.</p>
</li>
<li>
<p>Derrière, il donne des liens (pour mieux les critiquer ^^) vers les items pertinents de la FAQ lite.</p>
</li>
<li>
<p>Il a même <a href="https://yosefk.com/c++fqa/fqa.html#fqa-web-vs-fqa">une section consacrée aux points qu&#8217;il avance qui ont été invalidés</a>.</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_hakibenita_com_fast_load_data_python_postgresql_fastest_way_to_load_data_into_postgresql_using_python_a">[POST] <a href="https://hakibenita.com/fast-load-data-python-postgresql">Fastest Way to Load Data Into PostgreSQL Using Python</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_24_publié_le_2009_07_19_par_a_href_https_hakibenita_com_pages_about_haki_benita_a_pythonista_intéressé_par_webdev_databases_et_perfs_auteur_de_quelques_articles_sur_a_href_https_realpython_com_team_hbenita_realpython_a">Lu le 2020-02-24, publié le 2009-07-19 par <a href="https://hakibenita.com/pages/about">Haki BENITA</a>, pythonista intéressé par webdev, databases et perfs, auteur de quelques articles sur <a href="https://realpython.com/team/hbenita/">realpython</a></h3>
<div class="ulist">
<ul>
<li>
<p><strong>à retenir</strong> = pour peupler une DB postgres avec beaucoup de données, utiliser <code>COPY FROM</code> sur un fichier CSV (éventuellement, en RAM avec <code>StringIO</code>)</p>
<div class="quoteblock">
<blockquote>
If you are loading a freshly created table, the fastest method is to create the table, bulk load the table&#8217;s data using COPY, then create any indexes needed for the table.
</blockquote>
<div class="attribution">
&#8212; <a href="https://www.postgresql.org/docs/12/populate.html">doc postgres on populating a database</a>
</div>
</div>
</li>
<li>
<p>tooling sympa (indépendant de la problématique de l&#8217;article) :</p>
<div class="ulist">
<ul>
<li>
<p>une API de test rigolote <a href="https://punkapi.com/documentation/v2">pour requêter des bières</a> (usage : <code>curl <a href="https://api.punkapi.com/v2/beers/" class="bare">https://api.punkapi.com/v2/beers/</a></code>)</p>
</li>
<li>
<p><code>time.perf_counter()</code> est <a href="https://docs.python.org/3/library/time.html#time.perf_counter">plus adapté aux mesures de perfs que <code>time.time()</code></a></p>
</li>
<li>
<p>package <a href="https://pypi.org/project/memory-profiler/">memory-profiler</a> = pour profiler l&#8217;utilisation de la mémoire par une fonction, ligne par ligne</p>
</li>
</ul>
</div>
</li>
<li>
<p>problématique = méthode la plus rapide + la moins consommatrice de RAM pour peupler une DB postgres avec beaucoup de données ?</p>
</li>
<li>
<p>très lent (~ 2 minutes) = insérer les données ligne par ligne est très lent</p>
</li>
<li>
<p>rapide (~ 2 à 4 secondes) = insérer en batch, cf. psycopg2 <code>execute_batch</code> / <code>execute_values</code></p>
</li>
<li>
<p>très rapide (~ 0.5 secondes) = remplir un fichier CSV (en RAM avec StringIO), et utiliser un copy-from à partir de ça</p>
</li>
<li>
<p>et pour ne pas avoir à charger toutes les données en RAM, il créée un iterator custom sur ses données, qui présente l&#8217;interface d&#8217;un StringIO</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_www_joelonsoftware_com_2003_10_13_13_exceptions_a">[POST] <a href="https://www.joelonsoftware.com/2003/10/13/13/">Exceptions</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_22_publié_le_2003_10_13_par_a_href_https_www_joelonsoftware_com_joël_spolsky_a_dev_microsoft_sur_excel_co_créateur_de_stackoverflow_avec_jeff_atwood_créateur_de_trello">Lu le 2020-02-22, publié le 2003-10-13 par <a href="https://www.joelonsoftware.com/">Joël SPOLSKY</a>, dev Microsoft sur Excel, co-créateur de stackoverflow avec Jeff ATWOOD, créateur de Trello, &#8230;&#8203;</h3>
<div class="ulist">
<ul>
<li>
<p>Son avis sur les exceptions :</p>
<div class="ulist">
<ul>
<li>
<p>en pratique, ce sont des goto (i.e. jump vers un endroit arbitraire du code)</p>
</li>
<li>
<p>et même encore pire que goto : pas immédiatement visible dans le code-source + il y en a beaucoup au sein d&#8217;une même fonction</p>
</li>
</ul>
</div>
</li>
<li>
<p>Sa politique :</p>
<div class="ulist">
<ul>
<li>
<p>ne jamais lancer d&#8217;exceptions</p>
</li>
<li>
<p>si on doit utiliser du code qui peut throw, catcher <strong>dès la ligne d&#8217;appel</strong> même si c&#8217;est verbeux</p>
</li>
</ul>
</div>
</li>
<li>
<p>Le problème auquel répondent les exceptions = retourner DEUX return-values (la "vraie" return-value, et l&#8217;error-status) là où le langage n&#8217;en permet qu&#8217;un.</p>
</li>
<li>
<p>Il préfère retourner explicitement l&#8217;error-status (et donc passer un paramètre <code>T&amp; out</code> en argument pour stocker la vraie return-value) <strong>même si c&#8217;est BEAUCOUP plus verbeux</strong></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_blog_octo_com_reussir_la_developer_experience_de_son_api_web_réussir_la_developer_experience_de_son_api_web_a">[POST] <a href="https://blog.octo.com/reussir-la-developer-experience-de-son-api-web/">Réussir la Developer eXperience de son API web</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_18_publié_le_2020_02_18_par_a_href_https_blog_octo_com_octo_a">Lu le 2020-02-18, publié le 2020-02-18 par <a href="https://blog.octo.com">Octo</a></h3>
<div class="ulist">
<ul>
<li>
<p><strong>TL;DR</strong> : bonnes pratiques à suivre lorsqu&#8217;on ouvre ses APIs aux développeurs extérieurs</p>
</li>
<li>
<p>conception : faire rapidement des tests avec de vrais clients (éventuellement, POC-és)</p>
</li>
<li>
<p><strong>TTFAC</strong> = time to first API call = est-ce compliqué de bootstraper ce qui faut pour appeler l&#8217;API ? (s&#8217;il faut se farcier une doc de 30 pages : oui !)</p>
</li>
<li>
<p><strong>DX</strong> = Developer eXperience (à corréler à UX = User eXperience)</p>
</li>
<li>
<p>génération automatique de la doc : alternatives au très populaire swagger = <a href="https://apiblueprint.org/documentation/tutorial.html">API Blueprint</a> et <a href="https://raml.org/">RAML</a>.</p>
</li>
<li>
<p>points bonus : portail dev / sandbox / illustration (= exemples concrets) / SDK / assistance / communication</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_blog_octo_com_designer_une_api_rest_designer_une_api_rest_a">[POST] <a href="https://blog.octo.com/designer-une-api-rest/">Designer une API REST</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_18_publié_le_2014_12_01_par_a_href_https_blog_octo_com_octo_a">Lu le 2020-02-18, publié le 2014-12-01 par <a href="https://blog.octo.com">Octo</a></h3>
<div class="ulist">
<ul>
<li>
<p>affordance = capacité d&#8217;une API à suggérer son utilisation, pour limiter le besoin de recourir à la doc</p>
</li>
<li>
<p>il ne doit y avoir qu&#8217;une seule façon de faire les choses</p>
</li>
<li>
<p>suggestion = limiter les domaines à 3 :</p>
<div class="ulist">
<ul>
<li>
<p><code>api.fakecompany.com</code> = les appels à l&#8217;API</p>
</li>
<li>
<p><code>oauth2.fakecompany.com</code> = récupération d&#8217;un token pour utiliser l&#8217;API</p>
</li>
<li>
<p><code>dev.fakecompany.com</code> = portail develop de l&#8217;API</p>
</li>
</ul>
</div>
</li>
<li>
<p>distinguer case de l&#8217;URL et case du contenu (et au passage, je connaissais pas le nom de spinal-case=lisp-case)</p>
</li>
<li>
<p>versioning = dans l&#8217;URL, assez tôt, et doit être explicitement passé par les clients (pas de default-version)</p>
</li>
<li>
<p>réponse partielle = précisesr dans l&#8217;URL les champs qui nous intéressent (NdM : et GraphQL alors ?!)</p>
</li>
<li>
<p>pagination = à prévoir dès le début : query params + headers Content-Range et Accept-Ranges</p>
</li>
<li>
<p>lien vers "le reste" = <a href="https://tools.ietf.org/html/rfc5988">RFC5988</a> (NdM : HATEOAS) + <a href="https://developer.github.com/v3/#pagination">exemple de comment github fait</a></p>
</li>
<li>
<p>combinaison de pagination, filtre, tri</p>
</li>
<li>
<p>recherche = ressource à part entière</p>
</li>
<li>
<p>exception (qui doit rester exceptionnelle !) à la règle ressource=nom plutôt que verbe &#8594; non-ressource API (= service) &#8594; verbe. (e.g. un service "convert")</p>
</li>
<li>
<p>erreur : renvoyer 1. short description 2. long description 3. URI vers la doc de l&#8217;erreur</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_anaxi_com_blog_2019_02_20_how_to_make_other_developers_hate_to_work_with_you_how_to_make_other_developers_hate_to_work_with_you_a">[POST] <a href="https://anaxi.com/blog/2019/02/20/how-to-make-other-developers-hate-to-work-with-you/">How to Make Other Developers Hate to Work with You</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_02_18_publié_le_2019_02_20_par_a_href_https_anaxi_com_anaxi_a_tool_de_gestion_de_projet_saas">Lu le 2020-02-18, publié le 2019-02-20 par <a href="https://anaxi.com/">Anaxi</a>, tool de gestion de projet SAAS ?</h3>
<div class="ulist">
<ul>
<li>
<p>focus sur les défauts des développeurs, classés du plus impactant au moins impactant.</p>
</li>
<li>
<p><strong>arrogance</strong> : "as long as you take responsibility for and learn from your mistakes, you&#8217;re not a bad developer"</p>
</li>
<li>
<p><strong>sloppiness in the work delivered</strong> : beaucoup de choses ici, mais en gros : ne pas prendre le temps de faire les choses bien</p>
</li>
<li>
<p><strong>non-respect du temps des autres personnes</strong> : arriver en retard aux réunions, interrompre ses collègues, etc.</p>
</li>
<li>
<p><strong>négativité</strong> : toujours râler et critiquer, de façon non-constructive</p>
</li>
<li>
<p><strong>avarice</strong> : tirer la couverture à soi sur le travail réalisé</p>
</li>
<li>
<p><strong>disregard for the team</strong> : ignorer la big picture et les responsabilités des autres membres de l&#8217;équipe</p>
</li>
<li>
<p><strong>lack of focus</strong> : ignorer la big picture et se disperser</p>
</li>
<li>
<p><strong>lack of accountability</strong> : chercher des excuses au lieu de chercher des solutions</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_blog_feabhas_com_2014_03_demystifying_c_lambdas_demystifying_c_lambdas_a">[POST] <a href="https://blog.feabhas.com/2014/03/demystifying-c-lambdas/">Demystifying C++ lambdas</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_01_publié_le_2014_03_07_par_a_href_https_blog_feabhas_com_author_glennan_glennan_carnie_a_dev_embarqué_expérimenté">Lu le 2020-01-??, publié le 2014-03-07 par <a href="https://blog.feabhas.com/author/glennan/">Glennan CARNIE</a>, dev embarqué expérimenté</h3>
<div class="ulist">
<ul>
<li>
<p>Quel est l&#8217;intérêt de <code>std::function</code> ?</p>
</li>
<li>
<p>Il existe plusieurs types de callables :</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>pointeur de fonction</p>
</li>
<li>
<p>foncteur (= classe implémentant <code>operator()</code> )</p>
</li>
<li>
<p>pointeur de fonction membre</p>
</li>
<li>
<p>lambda</p>
</li>
<li>
<p><a href="https://en.cppreference.com/w/cpp/utility/functional/bind">bind-expression</a></p>
</li>
</ol>
</div>
</li>
<li>
<p>Comme ces objets sont différents, ils ont un type différent, et ça m&#8217;embête si je veux par exemple coder l&#8217;application d&#8217;un <code>processor</code> à tous les éléments d&#8217;un container de callables :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #66d9ef">void</span> <span style="color: #a6e22e">apply</span><span style="color: #f8f8f2">(Container</span><span style="color: #f92672">&amp;</span> <span style="color: #f8f8f2">container,</span> <span style="color: #f8f8f2">WhichTypeShouldIUse</span><span style="color: #f92672">&amp;</span> <span style="color: #f8f8f2">processor)</span> <span style="color: #f8f8f2">{</span> <span style="color: #f8f8f2">...</span> <span style="color: #f8f8f2">}</span></code></pre>
</div>
</div>
</li>
<li>
<p>Quel type utiliser à la place de <code>WhichTypeShouldIUse</code> ci-dessus ? <code>std::function</code> est conçu pour ça, et peut <a href="https://en.cppreference.com/w/cpp/utility/functional/function">représenter tout type de callable</a> :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #66d9ef">void</span> <span style="color: #a6e22e">apply</span><span style="color: #f8f8f2">(Container</span><span style="color: #f92672">&amp;</span> <span style="color: #f8f8f2">container,</span> <span style="color: #f8f8f2">std</span><span style="color: #f92672">::</span><span style="color: #f8f8f2">function</span><span style="color: #f92672">&lt;</span><span style="color: #66d9ef">void</span><span style="color: #f8f8f2">(</span><span style="color: #66d9ef">int</span><span style="color: #f8f8f2">)</span><span style="color: #f92672">&gt;&amp;</span> <span style="color: #f8f8f2">processor)</span> <span style="color: #f8f8f2">{</span> <span style="color: #f8f8f2">...</span> <span style="color: #f8f8f2">}</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__stackoverflow_a_href_https_stackoverflow_com_questions_7586939_is_int_safe_to_read_from_multiple_threads_7587008_7587008_is_int_safe_to_read_from_multiple_threads_a">[STACKOVERFLOW] <a href="https://stackoverflow.com/questions/7586939/is-int-safe-to-read-from-multiple-threads/7587008#7587008">Is int safe to read from multiple threads?</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_01_publié_le_2011_09_28_par_a_href_http_adamrosenfield_com_blog_about_adam_rosenfield_a_contributeur_hyperactif_de_stackoverflow_dev_amazon">Lu le 2020-01-??, publié le 2011-09-28 par <a href="http://adamrosenfield.com/blog/about/">Adam ROSENFIELD</a>, contributeur hyperactif de stackoverflow, dev amazon.</h3>
<div class="ulist">
<ul>
<li>
<p>l&#8217;une des utilisations du keyword <code>volatile</code> est de forcer le CPU à lire la valeur en mémoire sans la cacher, ce qui peut-être utile dans un contexte multithreadé.</p>
</li>
<li>
<p>attention toutefois, même en l&#8217;absence d&#8217;optimisation, <a href="https://en.cppreference.com/w/cpp/language/cv">il se peut qu&#8217;il reste d&#8217;autres problèmes, de reordering</a> :</p>
</li>
</ul>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>This makes volatile objects suitable for communication with a signal handler, but not with another thread of execution, see std::memory_order).</p>
</div>
</blockquote>
<div class="attribution">
&#8212; <a href="https://en.cppreference.com/w/cpp/language/cv">cppreference</a>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_manybutfinite_com_post_motherboard_chipsets_memory_map_motherboard_chipsets_and_the_memory_map_a">[POST] <a href="https://manybutfinite.com/post/motherboard-chipsets-memory-map/">Motherboard Chipsets and the Memory Map</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2020_01_publié_le_2008_06_04_par_a_href_https_manybutfinite_com_about_manybutfinite_a_blog_tech">Lu le 2020-01-??, publié le 2008-06-04 par <a href="https://manybutfinite.com/about/">manybutfinite</a>, blog tech</h3>
<div class="ulist">
<ul>
<li>
<p>CPU communique avec le monde extérieur via ses pins</p>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>In a motherboard the CPU&#8217;s gateway to the world is the front-side bus connecting it to the northbridge. Whenever the CPU needs to read or write memory it does so via this bus. It uses some pins to transmit the physical memory address it wants to write or read, while other pins send the value to be written or receive the value being read.</p>
</div>
</blockquote>
</div>
</li>
<li>
<p>les adresses vues par le CPU sont divisées en portions, dont certaines ne mappent même pas vers la RAM, mais plutôt vers des memory-mapped IO devices</p>
</li>
<li>
<p>le CPU n&#8217;a pas connaissance des devices à l&#8217;autre bout des adresses : pour lui, ce ne sont que des adresses</p>
</li>
<li>
<p>c&#8217;est le rôle du Northbridge de mapper les requêtes (en lecture ou écriture) sur une adresse vers d&#8217;autres devices que la RAM</p>
</li>
<li>
<p>(les adresses qui mappent sur la RAM sont les adresses physiques (nous, on n&#8217;a accès qu&#8217;aux adresses logiques, c&#8217;est le TLB qui mappe une adresse logique à une adresse phyisque)</p>
</li>
<li>
<p>memory address map</p>
<div class="ulist">
<ul>
<li>
<p>associe une plage d&#8217;adresses physiques à sa destination : RAM / video card / autre memory-mapped IO device</p>
</li>
<li>
<p>pour la consulter : <code>sudo cat /proc/iomem</code></p>
</li>
<li>
<p>il y a des "trous" dans les plages attribuées à la RAM, pour autre chose : BIOS / video card / carte de périphériques / carte PCI</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_id_liens_avec_des_notes_un_peu_touffues_a_a_href_https_lexi_lambda_github_io_blog_2019_11_05_parse_don_t_validate_parse_don_t_validate_a">[POST] <a id="liens-avec-des-notes-un-peu-touffues"></a><a href="https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/">Parse, don&#8217;t validate</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2019_11_publié_le_2019_11_05_par_a_href_https_lexi_lambda_github_io_alexis_king_a_webdev_spécialiste_d_haskell">Lu le 2019-11-??, publié le 2019-11-05 par <a href="https://lexi-lambda.github.io/">Alexis KING</a>, webdev spécialiste d&#8217;haskell</h3>
<div class="ulist">
<ul>
<li>
<p>quel est le type de retour d&#8217;une fonction qui renvoie le premier élément d&#8217;une liste de <code>T</code> ?</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>T</code> : non, car si la liste est vide, on ne renvoie pas <code>T</code></p>
</li>
<li>
<p><code>Maybe T</code> ? on renvoie <code>Just x</code>, ou <code>Nothing</code> si la liste est vide. Inconvénient = le client doit traiter le cas <code>Nothing</code>, même quand on est sûr que ça ne peut pas arriver.</p>
</li>
<li>
<p>on modifie le type d&#8217;entrée de la fonction pour n&#8217;accepter que des listes NonEmpty</p>
</li>
</ol>
</div>
</li>
<li>
<p>le truc cool : l&#8217;info <em>la liste n&#8217;est pas vide</em> est définie <em>DANS LE TYPE</em> : on a défini une précondition à la fonction, <em>mais qui est vérifiable statiquement au compile time</em></p>
</li>
<li>
<p>différence parse vs. validate :</p>
<div class="ulist">
<ul>
<li>
<p>validate = on vérifie la condition à un moment donné, mais on n&#8217;en fait rien (plus loin dans le code, elle pourrait redevenir fausse)</p>
</li>
<li>
<p>parse = on vérifie la condition, et on stocke l&#8217;info dans un type contraint (le compilo s&#8217;assure donc qu&#8217;elle ne pourra jamais redevenir fausse)</p>
</li>
</ul>
</div>
</li>
<li>
<p>mon exemple concret (pas dans l&#8217;article) :</p>
<div class="ulist">
<ul>
<li>
<p><strong>situation n°1</strong> = on représente une couleur avec un <code>int</code> :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #66d9ef">int</span> <span style="color: #a6e22e">parse</span><span style="color: #f8f8f2">(</span><span style="color: #66d9ef">const</span> <span style="color: #f8f8f2">InputFile</span><span style="color: #f92672">&amp;</span> <span style="color: #f8f8f2">f)</span>
<span style="color: #f8f8f2">{</span>
    <span style="color: #66d9ef">int</span> <span style="color: #f8f8f2">value</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">f.get_value();</span>
    <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">(value</span> <span style="color: #f92672">!=</span> <span style="color: #ae81ff">0</span> <span style="color: #f92672">||</span> <span style="color: #f8f8f2">value</span> <span style="color: #f92672">!=</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">)</span> <span style="color: #f8f8f2">{</span> <span style="color: #66d9ef">throw</span> <span style="color: #f8f8f2">std</span><span style="color: #f92672">::</span><span style="color: #f8f8f2">runtime_error(</span><span style="color: #e6db74">&quot;boum&quot;</span><span style="color: #f8f8f2">);</span> <span style="color: #f8f8f2">}</span>
    <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">value;</span>
<span style="color: #f8f8f2">}</span>
<span style="color: #66d9ef">int</span> <span style="color: #f8f8f2">color</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">parse(input_file);</span>
<span style="color: #75715e">// ... some stuff, maybe very long ...</span>

<span style="color: #75715e">// should I check again that color is in [0,1] ?</span>
<span style="color: #75715e">// if no, what happens if color is not in [0,1] anymore ?</span>
<span style="color: #66d9ef">void</span> <span style="color: #a6e22e">do_something</span><span style="color: #f8f8f2">(Color)</span> <span style="color: #f8f8f2">{</span> <span style="color: #75715e">/* something that relies on color being 0 or 1 */</span> <span style="color: #f8f8f2">}</span>
<span style="color: #f8f8f2">do_something(color);</span></code></pre>
</div>
</div>
</li>
<li>
<p><strong>situation n°2</strong> = on représente une couleur avec un <code>enum class Color</code> :</p>
<div class="listingblock">
<div class="content">
<pre class="pygments highlight"><code data-lang="cpp"><span style="color: #f8f8f2">Color</span> <span style="color: #a6e22e">parse</span><span style="color: #f8f8f2">(</span><span style="color: #66d9ef">const</span> <span style="color: #f8f8f2">InputFile</span><span style="color: #f92672">&amp;</span> <span style="color: #f8f8f2">f)</span>
<span style="color: #f8f8f2">{</span>
    <span style="color: #66d9ef">int</span> <span style="color: #f8f8f2">value</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">f.get_value();</span>
    <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">(value</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">0</span><span style="color: #f8f8f2">)</span> <span style="color: #f8f8f2">{</span> <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">Color</span><span style="color: #f92672">::</span><span style="color: #f8f8f2">RED;</span> <span style="color: #f8f8f2">}</span>
    <span style="color: #66d9ef">else</span> <span style="color: #66d9ef">if</span> <span style="color: #f8f8f2">(value</span> <span style="color: #f92672">==</span> <span style="color: #ae81ff">1</span><span style="color: #f8f8f2">)</span> <span style="color: #f8f8f2">{</span> <span style="color: #66d9ef">return</span> <span style="color: #f8f8f2">Color</span><span style="color: #f92672">::</span><span style="color: #f8f8f2">BLACK;</span> <span style="color: #f8f8f2">}</span>
    <span style="color: #66d9ef">else</span> <span style="color: #f8f8f2">{</span> <span style="color: #66d9ef">throw</span> <span style="color: #f8f8f2">std</span><span style="color: #f92672">::</span><span style="color: #f8f8f2">runtime_error(</span><span style="color: #e6db74">&quot;boum&quot;</span><span style="color: #f8f8f2">);</span> <span style="color: #f8f8f2">}</span>
<span style="color: #f8f8f2">}</span>
<span style="color: #f8f8f2">Color</span> <span style="color: #f8f8f2">color</span> <span style="color: #f92672">=</span> <span style="color: #f8f8f2">parse(input_file);</span>
<span style="color: #75715e">// ... some stuff, maybe very long ...</span>

<span style="color: #75715e">// no need to check again that color is in [0,1] : it&#39;s in the type !</span>
<span style="color: #66d9ef">void</span> <span style="color: #a6e22e">do_something</span><span style="color: #f8f8f2">(Color)</span> <span style="color: #f8f8f2">{</span> <span style="color: #75715e">/* something that relies on color being 0 or 1 */</span> <span style="color: #f8f8f2">}</span>
<span style="color: #f8f8f2">do_something(color);</span></code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>dans la situation n°1, il faut re-valider quand on utilise la couleur (danger si on oublie, ou si le code a évolué dans <code>parse</code> et qu&#8217;on a oublié de mettre à jour <code>do_something</code>, etc.). En bref, le compilo <em>NE RALERA PAS</em> si on passe la valeur <code>42</code> à <code>do_something</code>.</p>
</li>
<li>
<p>dans la situation n°2, la validation a été faite une fois pour toute, et le type system s&#8217;assure que <code>do_something</code> n&#8217;utilisera jamais de valeur invalide</p>
</li>
<li>
<p>parser en amont et utiliser un type contraint (plutôt que valider plus tard) est intéressant, car une fois le parsing fait, on ne manipule plus que des types toujours corrects</p>
</li>
<li>
<p>intérêt du type statique contraint = comme c&#8217;est le type qui véhicule l&#8217;info, il n&#8217;est même pas POSSIBLE d&#8217;avoir des valeurs incorrectes</p>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The problem is that validation-based approaches make it extremely difficult or impossible to determine if everything was actually validated up front or if some of those so-called “impossible” cases might actually happen. Parsing avoids this problem by stratifying the program into two phases—parsing and execution—where failure due to invalid input can only happen in the first phase.</p>
</div>
</blockquote>
</div>
</li>
<li>
<p>shotgun parsing = anti-pattern : le parsing/vérification de validité, est fait "tardivement" (voire au moment du processing), au lieu d&#8217;être faite une fois pour toute <em>en amont</em></p>
</li>
<li>
<p><strong>à retenir</strong> :</p>
<div class="ulist">
<ul>
<li>
<p>My advice: focus on the datatypes.</p>
</li>
<li>
<p>Use a data structure that makes illegal states unrepresentable</p>
</li>
<li>
<p>Push the burden of proof upward as far as possible (= parser au plus tôt les inputs en des types qui n&#8217;ont pas la possibilité de représenter des valeurs illégales)</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__site_a_href_https_pages_apigee_com_ebook_the_definitive_guide_to_api_management_register_html_the_definitive_guide_to_api_management_a">[SITE] <a href="https://pages.apigee.com/ebook-the-definitive-guide-to-api-management-register.html">The Definitive Guide to API Management</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2018_07_c_est_un_ebook_pour_avoir_un_overview_de_ce_que_propose_apigee">Lu le 2018-07-??, c&#8217;est un ebook pour avoir un overview de ce que propose apigee.</h3>
<div class="ulist">
<ul>
<li>
<p>fichier = <code>apigee-ebook-api-mgmt-2015-07.pdf</code></p>
</li>
<li>
<p>L&#8217;outil d&#8217;Apigee est :</p>
<div class="ulist">
<ul>
<li>
<p>Apigee EDGE API management product</p>
</li>
</ul>
</div>
</li>
<li>
<p>API management tool = une solution qui permet :</p>
<div class="ulist">
<ul>
<li>
<p>un portail pour développeurs : découvrir, explorer, acheter, tester, s&#8217;enregistrer pour utiliser des API</p>
</li>
<li>
<p>une passerelle d&#8217;API : sécuriser et gérer le traffic entre les clients et les backends, et plus généralement entre une API et ses utilisateurs</p>
</li>
<li>
<p>un gestionnaire de cycle de vie : gérer la conception, le développement, la publication, le déploiement, et le versioning des API</p>
</li>
<li>
<p>éventuellement, un outil d&#8217;analyse d&#8217;utilisation des API, orienté business</p>
</li>
<li>
<p>éventuellement, un outil de monetization pour packager, pricer et publier les APIs, et pour faire payer les clients</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_blog_eleven_labs_com_fr_presentation_protocol_buffers_présentation_de_protocol_buffers_a">[POST] <a href="https://blog.eleven-labs.com/fr/presentation-protocol-buffers/">Présentation de Protocol Buffers</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2018_06_publié_le_2017_09_20_sur_a_href_https_blog_eleven_labs_com_le_blog_d_eleven_labs_a_ssii">Lu le 2018-06-??, publié le 2017-09-20 sur <a href="https://blog.eleven-labs.com/">le blog d&#8217;Eleven Labs</a>, SSII.</h3>
<div class="ulist">
<ul>
<li>
<p>Protobuf est un système de sérialisation de données (comme json ou XML) binaire.</p>
<div class="ulist">
<ul>
<li>
<p>&#43;&#43;&#43; : language-agnostic : on décrit les données dans un fichier .proto, puis un outil (protoc) génère le code de (dé)sérialization pour le langage voulu.</p>
</li>
<li>
<p>&#43;&#43;&#43; : très performant (aussi bien sur la taille de la donnée encodée, que sur la vitesse de (dé)sérialization)</p>
</li>
<li>
<p>--- : message en binaire plus dur à débugger que du json</p>
</li>
<li>
<p>--- : on a une couche de complexité (le fichier proto) en plus</p>
</li>
</ul>
</div>
</li>
<li>
<p>(langage-agnostic utile dans une architecture micro-services où chaque service doit communiquer avec d’autres quel que soit le langage)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_evertpot_com_dropbox_post_api_dropbox_starts_using_post_and_why_this_is_poor_api_design_a">[POST] <a href="https://evertpot.com/dropbox-post-api/">Dropbox starts using POST, and why this is poor API design</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2018_05_publié_le_2015_03_02_par_a_href_https_evertpot_com_evert_pot_a_un_dev_web_avec_un_focus_sur_les_apis_et_http">Lu le 2018-05-??, publié le 2015-03-02 par <a href="https://evertpot.com/">Evert Pot</a>, un dev web avec un focus sur les APIs et HTTP.</h3>
<div class="ulist">
<ul>
<li>
<p>Utiliser des requêtes GET pour développer des APIs peut-être compliqué :</p>
<div class="ulist">
<ul>
<li>
<p>limitation du volume de données qu&#8217;on peut transmettre dans une URL</p>
</li>
<li>
<p>mettre des données dans l&#8217;URL est moins flexible que dans le body (notamment : json ?)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Du coup, dropbox permet le POST là où avant on ne pouvait que le GET.</p>
</li>
<li>
<p>Problème avec POST = non-safe / non-idempotent &#8594; non-cachable (notamment par les proxies).</p>
</li>
<li>
<p>Solutions possibles :</p>
<div class="ulist">
<ul>
<li>
<p>Utiliser REPORT (safe + idempotent + body autorisé), verbe défini dans une extension WEBDAV à HTTP.</p>
</li>
<li>
<p>Utiliser GET avec un body : BAD car l&#8217;intérêt du GET (caching) est perdu + HTTP dit explicitement que le body n&#8217;a pas de sens.</p>
</li>
<li>
<p>(side-note : le gros intérêt de GET, c&#8217;est l&#8217;adressabilité &#8594; permettre de faire un simple lien vers une ressource est le top !)</p>
</li>
<li>
<p>Décorréler la requête (faite avec POST, donc avec body) et la récupération de la réponse (faite sur une autre URL, récupérée avec GET)</p>
</li>
</ul>
</div>
</li>
<li>
<p>Plus de détail sur cette dernière solution :</p>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>le client fait un POST sur "/queries"  (en passant ce qu&#8217;il souhaite dans le body)</p>
</li>
<li>
<p>le serveur répond à cette requête POST en indiquant dans le header "Content-Location" une URL gettable : p.ex. "/queries/42"</p>
</li>
<li>
<p>le client fait un GET sur "/queries/42" pour récupérer sa réponse</p>
</li>
</ol>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__post_a_href_https_blog_philipphauer_de_dont_share_libraries_among_microservices_don_t_share_libraries_among_microservices_a">[POST] <a href="https://blog.philipphauer.de/dont-share-libraries-among-microservices/">Don&#8217;t Share Libraries among Microservices</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_lu_le_2018_05_publié_le_2016_04_17_sur_a_href_https_phauer_com_le_blog_de_philipp_hauer_a_dev_java_kotlin">Lu le 2018-05-??, publié le 2016-04-17 sur <a href="https://phauer.com/">le blog de Philipp HAUER</a>, dev java/kotlin.</h3>
<div class="ulist">
<ul>
<li>
<p>Si des microservices utilisent la même librairie, ils sont couplés.</p>
<div class="ulist">
<ul>
<li>
<p>On va les livrer plus souvent, on va avoir plus de bugs.</p>
</li>
<li>
<p>De plus, on va naturellement mettre la librairie à jour moins souvent.</p>
</li>
<li>
<p>Et ça induit des problèmes de dépendances.</p>
</li>
</ul>
</div>
</li>
<li>
<p><em>“Duplication is better than the wrong abstraction”</em></p>
</li>
<li>
<p>Pistes de solutions :</p>
<div class="ulist">
<ul>
<li>
<p>accepter d&#8217;avoir de la redondance pour rester indépendant</p>
</li>
<li>
<p>sortir la librairie dans un SERVICE partagé (plutôt qu&#8217;une lib partagée)</p>
</li>
<li>
<p>refactorer les microservices (ou leur architecture) pour ne plus avoir besoin de partager la librairie</p>
</li>
</ul>
</div>
</li>
<li>
<p>contexte au travail : je fais le lien avec lbsserver/lbsdevtool, utilisées par routemm, et qu&#8217;on ne maintient jamais&#8230;&#8203;</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="__bbl_no_estimates">[BBL] No estimates</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_présentation_le_2018_12_05_par_a_href_https_twitter_com_julientopcu_lang_fr_julien_topÇu_a_de_la_société_générale">Présentation le 2018-12-05, par <a href="https://twitter.com/julientopcu?lang=fr">Julien TOPÇU</a> de la Société Générale</h3>
<div class="sect3">
<h4 id="_tout_un_tas_de_notions_vrac_pour_la_culture_générale">Tout un tas de notions vrac pour la culture générale</h4>
<div class="ulist">
<ul>
<li>
<p>Tel ticket = notre référence-unité, on chiffre tous les autres par rapport à ça.</p>
</li>
<li>
<p>Le titre "No Estimates" n&#8217;est pas forcément pertinent, c&#8217;est plutôt une provocation : en effet, l&#8217;idée n&#8217;est pas de ne plus estimer les tâches, l&#8217;idée est plutôt de lutter contre la tendance qu&#8217;on a à tout driver par le chiffrage.</p>
</li>
<li>
<p>Vasco DUARTE = chantre du NoEstimates (<a href="https://twitter.com/duarte_vasco" class="bare">https://twitter.com/duarte_vasco</a>)</p>
</li>
<li>
<p>Kent BECK = fondateur de l&#8217;extreme programming)</p>
</li>
<li>
<p>Loi de Conway = le design reflète l&#8217;organisation de la structure.</p>
</li>
<li>
<p>Loi de Hofstadter = on utilise toujours tout le temps alloué, et même plus (<a href="https://fr.wikipedia.org/wiki/Loi_de_Hofstadter" class="bare">https://fr.wikipedia.org/wiki/Loi_de_Hofstadter</a>)</p>
</li>
<li>
<p>Distinguer deux types de complexité :</p>
<div class="ulist">
<ul>
<li>
<p>essentielle = dûe au métier, qui est complexe (impossible de la réduire sans modifier le métier)</p>
</li>
<li>
<p>accidentelle = dûe à d&#8217;autres choses (e.g. dette technique), qu&#8217;on peut réduire en faisant autrement</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_le_noestimates">Le NoEstimates</h4>
<div class="ulist">
<ul>
<li>
<p>Même en NoEstimates, le besoin reste le même = visibilité + aide à la décision</p>
</li>
<li>
<p>L&#8217;idée principale, c&#8217;est de calculer des métriques (cycle time, vélocité) en s&#8217;aidant du passé, puis de faire de l&#8217;analyse statistique dessus pour en déduire une probabilité raisonnable sur la réalisation d&#8217;un périmètre fonctionnel</p>
</li>
<li>
<p>Un point important (qui disqualifie probablement la méthode pour notre équipe), c&#8217;est la STABILITÉ de notre cycle-time et de nos métriques.</p>
</li>
<li>
<p>Cependant, je retiens un conseil réalisable en pratique :</p>
<div class="ulist">
<ul>
<li>
<p>on se fixe une taille de référence en pratique pour une tâche (e.g. 4 jours, dont 2 de dev, et le reste en review/release)</p>
</li>
<li>
<p>en sprint planning, l&#8217;objectif est de n&#8217;avoir des story QUE de cette taille de référence</p>
</li>
<li>
<p>les stories plus petites sont mergées pour atteindre 4</p>
</li>
<li>
<p>les stories plus grandes sont splittées pour atteindre 4</p>
</li>
<li>
<p>avantage = plus de visibilité sur les stories</p>
</li>
<li>
<p>inconvénient = pas forcément facile (et parfois long et coûteux) de découper pour atteindre la taille souhaitée</p>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>

    

  </body>
</html>
